{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12760936,"sourceType":"datasetVersion","datasetId":8066839}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Dataset Creation after combining all the CSVs for model training","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport os\nimport re\n\nfolder_path = \"/kaggle/input/flexural-raw-data/Abhishek Raw Data\"\ncsv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n\ndfs = []\n\n# Robust function to extract pattern, density, and code\ndef extract_pattern_density_code(filename):\n    name = filename.split('.')[0]  # remove extension\n    match = re.match(r\"([A-Z0-9]+?)(\\d+)(\\d{1,3})$\", name)\n    if match:\n        pattern = match.group(1)\n        density = int(match.group(2))\n        code = int(match.group(3))\n        return pattern, density, code\n    else:\n        print(f\"Filename did not match expected pattern: {filename}\")\n        return None, None, None\n\nfor file in csv_files:\n    df = pd.read_csv(os.path.join(folder_path, file))\n    pattern, density, code = extract_pattern_density_code(file)\n    df['Pattern'] = pattern\n    df['Density'] = density\n    df['Code'] = density*10 + code\n    dfs.append(df)\n\nmaster_df = pd.concat(dfs, ignore_index=True)\n\nprint(\"Master CSV created successfully!\")\nprint(master_df.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T16:43:53.967108Z","iopub.execute_input":"2025-08-15T16:43:53.967455Z","iopub.status.idle":"2025-08-15T16:44:04.648120Z","shell.execute_reply.started":"2025-08-15T16:43:53.967426Z","shell.execute_reply":"2025-08-15T16:44:04.647372Z"}},"outputs":[{"name":"stdout","text":"Master CSV created successfully!\n      Time Flexure extension Flexure load Flexure strain Flexure stress  \\\n0    (sec)              (mm)          (N)            (%)          (MPa)   \n1  0.00000           0.00000      0.01663        0.00000        0.00998   \n2  0.05000           0.00000      0.02967        0.00000        0.01780   \n3  0.10000           0.00000      0.01669        0.00000        0.01001   \n4  0.15000           0.00031      0.05049        0.00018        0.03029   \n\n  Extension      Load Pattern  Density  Code  \n0      (mm)       (N)     TRI       80   802  \n1   0.00000  -0.01663     TRI       80   802  \n2   0.00000  -0.02967     TRI       80   802  \n3   0.00000  -0.01669     TRI       80   802  \n4  -0.00031  -0.05049     TRI       80   802  \n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"master_df.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T16:44:04.649456Z","iopub.execute_input":"2025-08-15T16:44:04.649748Z","iopub.status.idle":"2025-08-15T16:44:04.656143Z","shell.execute_reply.started":"2025-08-15T16:44:04.649726Z","shell.execute_reply":"2025-08-15T16:44:04.655276Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"(2027904, 10)"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"master_df.head(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T16:44:04.657086Z","iopub.execute_input":"2025-08-15T16:44:04.657347Z","iopub.status.idle":"2025-08-15T16:44:04.728795Z","shell.execute_reply.started":"2025-08-15T16:44:04.657316Z","shell.execute_reply":"2025-08-15T16:44:04.727870Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"      Time Flexure extension Flexure load Flexure strain Flexure stress  \\\n0    (sec)              (mm)          (N)            (%)          (MPa)   \n1  0.00000           0.00000      0.01663        0.00000        0.00998   \n2  0.05000           0.00000      0.02967        0.00000        0.01780   \n3  0.10000           0.00000      0.01669        0.00000        0.01001   \n4  0.15000           0.00031      0.05049        0.00018        0.03029   \n5  0.20000           0.00047      0.06700        0.00027        0.04020   \n6  0.25000           0.00187      0.05096        0.00110        0.03057   \n7  0.30000           0.00328      0.03393        0.00192        0.02036   \n8  0.35000           0.00516      0.04957        0.00302        0.02974   \n9  0.40000           0.00734      0.05833        0.00430        0.03500   \n\n  Extension      Load Pattern  Density  Code  \n0      (mm)       (N)     TRI       80   802  \n1   0.00000  -0.01663     TRI       80   802  \n2   0.00000  -0.02967     TRI       80   802  \n3   0.00000  -0.01669     TRI       80   802  \n4  -0.00031  -0.05049     TRI       80   802  \n5  -0.00047  -0.06700     TRI       80   802  \n6  -0.00187  -0.05096     TRI       80   802  \n7  -0.00328  -0.03393     TRI       80   802  \n8  -0.00516  -0.04957     TRI       80   802  \n9  -0.00734  -0.05833     TRI       80   802  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Time</th>\n      <th>Flexure extension</th>\n      <th>Flexure load</th>\n      <th>Flexure strain</th>\n      <th>Flexure stress</th>\n      <th>Extension</th>\n      <th>Load</th>\n      <th>Pattern</th>\n      <th>Density</th>\n      <th>Code</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>(sec)</td>\n      <td>(mm)</td>\n      <td>(N)</td>\n      <td>(%)</td>\n      <td>(MPa)</td>\n      <td>(mm)</td>\n      <td>(N)</td>\n      <td>TRI</td>\n      <td>80</td>\n      <td>802</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.01663</td>\n      <td>0.00000</td>\n      <td>0.00998</td>\n      <td>0.00000</td>\n      <td>-0.01663</td>\n      <td>TRI</td>\n      <td>80</td>\n      <td>802</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.05000</td>\n      <td>0.00000</td>\n      <td>0.02967</td>\n      <td>0.00000</td>\n      <td>0.01780</td>\n      <td>0.00000</td>\n      <td>-0.02967</td>\n      <td>TRI</td>\n      <td>80</td>\n      <td>802</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.10000</td>\n      <td>0.00000</td>\n      <td>0.01669</td>\n      <td>0.00000</td>\n      <td>0.01001</td>\n      <td>0.00000</td>\n      <td>-0.01669</td>\n      <td>TRI</td>\n      <td>80</td>\n      <td>802</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.15000</td>\n      <td>0.00031</td>\n      <td>0.05049</td>\n      <td>0.00018</td>\n      <td>0.03029</td>\n      <td>-0.00031</td>\n      <td>-0.05049</td>\n      <td>TRI</td>\n      <td>80</td>\n      <td>802</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.20000</td>\n      <td>0.00047</td>\n      <td>0.06700</td>\n      <td>0.00027</td>\n      <td>0.04020</td>\n      <td>-0.00047</td>\n      <td>-0.06700</td>\n      <td>TRI</td>\n      <td>80</td>\n      <td>802</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.25000</td>\n      <td>0.00187</td>\n      <td>0.05096</td>\n      <td>0.00110</td>\n      <td>0.03057</td>\n      <td>-0.00187</td>\n      <td>-0.05096</td>\n      <td>TRI</td>\n      <td>80</td>\n      <td>802</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.30000</td>\n      <td>0.00328</td>\n      <td>0.03393</td>\n      <td>0.00192</td>\n      <td>0.02036</td>\n      <td>-0.00328</td>\n      <td>-0.03393</td>\n      <td>TRI</td>\n      <td>80</td>\n      <td>802</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.35000</td>\n      <td>0.00516</td>\n      <td>0.04957</td>\n      <td>0.00302</td>\n      <td>0.02974</td>\n      <td>-0.00516</td>\n      <td>-0.04957</td>\n      <td>TRI</td>\n      <td>80</td>\n      <td>802</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.40000</td>\n      <td>0.00734</td>\n      <td>0.05833</td>\n      <td>0.00430</td>\n      <td>0.03500</td>\n      <td>-0.00734</td>\n      <td>-0.05833</td>\n      <td>TRI</td>\n      <td>80</td>\n      <td>802</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"master_df['Density'].unique()  # Shows all unique densities","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T16:44:04.730965Z","iopub.execute_input":"2025-08-15T16:44:04.731261Z","iopub.status.idle":"2025-08-15T16:44:04.755303Z","shell.execute_reply.started":"2025-08-15T16:44:04.731239Z","shell.execute_reply":"2025-08-15T16:44:04.754508Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"array([ 80, 100,  40,  20,  60])"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"master_df['Pattern'].unique()  # Shows all unique densities","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T16:44:04.756041Z","iopub.execute_input":"2025-08-15T16:44:04.756277Z","iopub.status.idle":"2025-08-15T16:44:04.877347Z","shell.execute_reply.started":"2025-08-15T16:44:04.756258Z","shell.execute_reply":"2025-08-15T16:44:04.876450Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"array(['TRI', 'OCT', 'LIG', 'CON', 'GRI', 'LIN', 'C3D', 'CSD', 'QCU',\n       'CRS', 'ZZG', 'THX', 'CUB', 'GYR'], dtype=object)"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"master_df['Code'].unique()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T16:44:04.878405Z","iopub.execute_input":"2025-08-15T16:44:04.878715Z","iopub.status.idle":"2025-08-15T16:44:04.898505Z","shell.execute_reply.started":"2025-08-15T16:44:04.878686Z","shell.execute_reply":"2025-08-15T16:44:04.897672Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"array([ 802, 1001, 1003,  402,  201,  803,  801,  202,  203,  603,  601,\n       1002,  403,  602,  401])"},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"\nimport pandas as pd\n\n# Assuming master_df is your dataframe\nunits_pattern = ['(sec)', '(mm)', '(N)', '(%)', '(MPa)', '(mm)', '(N)']\n\n# Identify rows containing all the unit values\nmatching_rows = master_df.apply(lambda row: all(item in row.values for item in units_pattern), axis=1)\n\n# Get the indices of these rows\nrow_indices = master_df.index[matching_rows].tolist()\nprint(\"Row indices containing units:\", row_indices)\n\n# Optionally, print the first few matching rows\nprint(\"\\nSome matching rows:\")\nprint(master_df.loc[row_indices].head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T16:44:04.899457Z","iopub.execute_input":"2025-08-15T16:44:04.899769Z","iopub.status.idle":"2025-08-15T16:44:31.198091Z","shell.execute_reply.started":"2025-08-15T16:44:04.899741Z","shell.execute_reply":"2025-08-15T16:44:31.197160Z"}},"outputs":[{"name":"stdout","text":"Row indices containing units: [0, 9668, 20318, 30332, 40040, 49837, 59627, 66874, 76546, 86182, 96060, 107345, 121478, 128721, 140013, 147235, 158219, 175072, 184776, 192812, 202681, 212314, 220429, 230074, 239747, 247860, 259058, 270715, 280350, 290104, 299733, 308090, 318526, 328484, 338925, 346961, 359109, 368923, 379389, 389114, 398819, 408709, 418540, 428407, 436456, 446113, 455795, 465508, 477637, 487452, 497947, 505185, 513210, 523059, 534407, 542508, 553003, 562824, 572554, 583066, 592734, 600772, 610523, 621765, 631567, 641275, 650915, 659000, 669521, 677545, 688804, 700096, 707541, 718253, 727297, 737636, 745721, 755368, 765139, 775611, 785287, 794925, 805388, 813461, 824291, 832325, 843580, 851842, 861383, 872649, 882341, 893673, 904120, 914189, 922316, 930364, 937591, 944853, 961676, 971391, 981041, 989224, 999015, 1008684, 1018359, 1028898, 1038569, 1048348, 1058000, 1067866, 1077681, 1088179, 1095430, 1102652, 1112293, 1119531, 1130774, 1140425, 1147662, 1154724, 1162778, 1170028, 1180100, 1188517, 1196552, 1207937, 1215999, 1226432, 1234489, 1246006, 1256435, 1266168, 1276607, 1286466, 1294845, 1304412, 1311651, 1321295, 1332543, 1349641, 1360464, 1371695, 1381421, 1388666, 1396800, 1407243, 1415272, 1425726, 1436129, 1444172, 1455572, 1465207, 1476557, 1487824, 1497467, 1506617, 1516307, 1523543, 1533179, 1540429, 1547690, 1554929, 1566213, 1577492, 1587132, 1596757, 1605002, 1614902, 1624661, 1635593, 1646269, 1656040, 1663182, 1674442, 1682531, 1692697, 1704016, 1713557, 1721628, 1732901, 1742606, 1749861, 1759831, 1766359, 1774428, 1784156, 1793787, 1805926, 1816378, 1826005, 1835810, 1842955, 1853395, 1863226, 1872882, 1881080, 1891513, 1901267, 1909300, 1920588, 1931071, 1940712, 1950348, 1960089, 1969741, 1979369, 1990635, 2000316, 2008579, 2018228]\n\nSome matching rows:\n        Time Flexure extension Flexure load Flexure strain Flexure stress  \\\n0      (sec)              (mm)          (N)            (%)          (MPa)   \n9668   (sec)              (mm)          (N)            (%)          (MPa)   \n20318  (sec)              (mm)          (N)            (%)          (MPa)   \n30332  (sec)              (mm)          (N)            (%)          (MPa)   \n40040  (sec)              (mm)          (N)            (%)          (MPa)   \n\n      Extension Load Pattern  Density  Code  \n0          (mm)  (N)     TRI       80   802  \n9668       (mm)  (N)     OCT       80   802  \n20318      (mm)  (N)     LIG      100  1001  \n30332      (mm)  (N)     CON      100  1001  \n40040      (mm)  (N)     GRI      100  1003  \n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"master_df.loc[9668]    # by index label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T16:44:31.199040Z","iopub.execute_input":"2025-08-15T16:44:31.199378Z","iopub.status.idle":"2025-08-15T16:44:31.206557Z","shell.execute_reply.started":"2025-08-15T16:44:31.199329Z","shell.execute_reply":"2025-08-15T16:44:31.205709Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"Time                 (sec)\nFlexure extension     (mm)\nFlexure load           (N)\nFlexure strain         (%)\nFlexure stress       (MPa)\nExtension             (mm)\nLoad                   (N)\nPattern                OCT\nDensity                 80\nCode                   802\nName: 9668, dtype: object"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"master_df.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T16:44:31.207451Z","iopub.execute_input":"2025-08-15T16:44:31.208339Z","iopub.status.idle":"2025-08-15T16:44:31.228190Z","shell.execute_reply.started":"2025-08-15T16:44:31.208316Z","shell.execute_reply":"2025-08-15T16:44:31.227404Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"(2027904, 10)"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"import pandas as pd\n\n# Define the units pattern\nunits_pattern = ['(sec)', '(mm)', '(N)', '(%)', '(MPa)', '(mm)', '(N)']\n\n# Identify rows containing all unit values\nmatching_rows = master_df.apply(lambda row: all(item in row.values for item in units_pattern), axis=1)\n\n# Drop these rows\ndf = master_df[~matching_rows].reset_index(drop=True)\n\nprint(\"Rows containing units have been removed. New dataframe shape:\", df.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T16:44:31.231242Z","iopub.execute_input":"2025-08-15T16:44:31.232226Z","iopub.status.idle":"2025-08-15T16:44:58.464575Z","shell.execute_reply.started":"2025-08-15T16:44:31.232199Z","shell.execute_reply":"2025-08-15T16:44:58.463531Z"}},"outputs":[{"name":"stdout","text":"Rows containing units have been removed. New dataframe shape: (2027694, 10)\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"df.head(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T16:44:58.465499Z","iopub.execute_input":"2025-08-15T16:44:58.465716Z","iopub.status.idle":"2025-08-15T16:44:58.477854Z","shell.execute_reply.started":"2025-08-15T16:44:58.465698Z","shell.execute_reply":"2025-08-15T16:44:58.476972Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"      Time Flexure extension Flexure load Flexure strain Flexure stress  \\\n0  0.00000           0.00000      0.01663        0.00000        0.00998   \n1  0.05000           0.00000      0.02967        0.00000        0.01780   \n2  0.10000           0.00000      0.01669        0.00000        0.01001   \n3  0.15000           0.00031      0.05049        0.00018        0.03029   \n4  0.20000           0.00047      0.06700        0.00027        0.04020   \n5  0.25000           0.00187      0.05096        0.00110        0.03057   \n6  0.30000           0.00328      0.03393        0.00192        0.02036   \n7  0.35000           0.00516      0.04957        0.00302        0.02974   \n8  0.40000           0.00734      0.05833        0.00430        0.03500   \n9  0.45000           0.00953      0.08730        0.00558        0.05238   \n\n  Extension      Load Pattern  Density  Code  \n0   0.00000  -0.01663     TRI       80   802  \n1   0.00000  -0.02967     TRI       80   802  \n2   0.00000  -0.01669     TRI       80   802  \n3  -0.00031  -0.05049     TRI       80   802  \n4  -0.00047  -0.06700     TRI       80   802  \n5  -0.00187  -0.05096     TRI       80   802  \n6  -0.00328  -0.03393     TRI       80   802  \n7  -0.00516  -0.04957     TRI       80   802  \n8  -0.00734  -0.05833     TRI       80   802  \n9  -0.00953  -0.08730     TRI       80   802  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Time</th>\n      <th>Flexure extension</th>\n      <th>Flexure load</th>\n      <th>Flexure strain</th>\n      <th>Flexure stress</th>\n      <th>Extension</th>\n      <th>Load</th>\n      <th>Pattern</th>\n      <th>Density</th>\n      <th>Code</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.01663</td>\n      <td>0.00000</td>\n      <td>0.00998</td>\n      <td>0.00000</td>\n      <td>-0.01663</td>\n      <td>TRI</td>\n      <td>80</td>\n      <td>802</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.05000</td>\n      <td>0.00000</td>\n      <td>0.02967</td>\n      <td>0.00000</td>\n      <td>0.01780</td>\n      <td>0.00000</td>\n      <td>-0.02967</td>\n      <td>TRI</td>\n      <td>80</td>\n      <td>802</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.10000</td>\n      <td>0.00000</td>\n      <td>0.01669</td>\n      <td>0.00000</td>\n      <td>0.01001</td>\n      <td>0.00000</td>\n      <td>-0.01669</td>\n      <td>TRI</td>\n      <td>80</td>\n      <td>802</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.15000</td>\n      <td>0.00031</td>\n      <td>0.05049</td>\n      <td>0.00018</td>\n      <td>0.03029</td>\n      <td>-0.00031</td>\n      <td>-0.05049</td>\n      <td>TRI</td>\n      <td>80</td>\n      <td>802</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.20000</td>\n      <td>0.00047</td>\n      <td>0.06700</td>\n      <td>0.00027</td>\n      <td>0.04020</td>\n      <td>-0.00047</td>\n      <td>-0.06700</td>\n      <td>TRI</td>\n      <td>80</td>\n      <td>802</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.25000</td>\n      <td>0.00187</td>\n      <td>0.05096</td>\n      <td>0.00110</td>\n      <td>0.03057</td>\n      <td>-0.00187</td>\n      <td>-0.05096</td>\n      <td>TRI</td>\n      <td>80</td>\n      <td>802</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.30000</td>\n      <td>0.00328</td>\n      <td>0.03393</td>\n      <td>0.00192</td>\n      <td>0.02036</td>\n      <td>-0.00328</td>\n      <td>-0.03393</td>\n      <td>TRI</td>\n      <td>80</td>\n      <td>802</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.35000</td>\n      <td>0.00516</td>\n      <td>0.04957</td>\n      <td>0.00302</td>\n      <td>0.02974</td>\n      <td>-0.00516</td>\n      <td>-0.04957</td>\n      <td>TRI</td>\n      <td>80</td>\n      <td>802</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.40000</td>\n      <td>0.00734</td>\n      <td>0.05833</td>\n      <td>0.00430</td>\n      <td>0.03500</td>\n      <td>-0.00734</td>\n      <td>-0.05833</td>\n      <td>TRI</td>\n      <td>80</td>\n      <td>802</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.45000</td>\n      <td>0.00953</td>\n      <td>0.08730</td>\n      <td>0.00558</td>\n      <td>0.05238</td>\n      <td>-0.00953</td>\n      <td>-0.08730</td>\n      <td>TRI</td>\n      <td>80</td>\n      <td>802</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"# Example: drop the column named 'Extension'\ndf = df.drop(columns=['Time','Code'])\n\n# Verify\nprint(df.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T16:44:58.478718Z","iopub.execute_input":"2025-08-15T16:44:58.479008Z","iopub.status.idle":"2025-08-15T16:44:58.639234Z","shell.execute_reply.started":"2025-08-15T16:44:58.478987Z","shell.execute_reply":"2025-08-15T16:44:58.638270Z"}},"outputs":[{"name":"stdout","text":"  Flexure extension Flexure load Flexure strain Flexure stress Extension  \\\n0           0.00000      0.01663        0.00000        0.00998   0.00000   \n1           0.00000      0.02967        0.00000        0.01780   0.00000   \n2           0.00000      0.01669        0.00000        0.01001   0.00000   \n3           0.00031      0.05049        0.00018        0.03029  -0.00031   \n4           0.00047      0.06700        0.00027        0.04020  -0.00047   \n\n       Load Pattern  Density  \n0  -0.01663     TRI       80  \n1  -0.02967     TRI       80  \n2  -0.01669     TRI       80  \n3  -0.05049     TRI       80  \n4  -0.06700     TRI       80  \n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"df = df.sample(frac=1, random_state=42).reset_index(drop=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T16:44:58.640165Z","iopub.execute_input":"2025-08-15T16:44:58.640435Z","iopub.status.idle":"2025-08-15T16:45:02.036139Z","shell.execute_reply.started":"2025-08-15T16:44:58.640412Z","shell.execute_reply":"2025-08-15T16:45:02.035230Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T16:45:02.037040Z","iopub.execute_input":"2025-08-15T16:45:02.037306Z","iopub.status.idle":"2025-08-15T16:45:02.050174Z","shell.execute_reply.started":"2025-08-15T16:45:02.037283Z","shell.execute_reply":"2025-08-15T16:45:02.049096Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"        Flexure extension Flexure load Flexure strain Flexure stress  \\\n0                 5.09750     87.61620        2.98682       52.56971   \n1                20.62094     94.02350       12.08258       56.41410   \n2                 2.57016     44.17989        1.50595       26.50793   \n3                10.31719     72.81451        6.04523       43.68870   \n4                 3.91109     55.16191        2.29166       33.09715   \n...                   ...          ...            ...            ...   \n2027689           0.18234      0.04409        0.10684        0.02646   \n2027690           9.14500     71.02377        5.35840       42.61426   \n2027691           4.03016     57.97430        2.36142       34.78458   \n2027692           2.12766     34.03754        1.24667       20.42252   \n2027693           0.61500      6.52319        0.36035        3.91391   \n\n         Extension       Load Pattern  Density  \n0         -5.09750  -87.61619     CUB       80  \n1        -20.62094  -94.02350     CUB      100  \n2         -2.57016  -44.17988     OCT      100  \n3        -10.31719  -72.81451     QCU       20  \n4         -3.91109  -55.16191     LIN       60  \n...            ...        ...     ...      ...  \n2027689   -0.18234   -0.04409     LIN       60  \n2027690   -9.14500  -71.02377     CUB       20  \n2027691   -4.03016  -57.97430     ZZG       60  \n2027692   -2.12766  -34.03754     CUB       40  \n2027693   -0.61500   -6.52319     CRS       20  \n\n[2027694 rows x 8 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Flexure extension</th>\n      <th>Flexure load</th>\n      <th>Flexure strain</th>\n      <th>Flexure stress</th>\n      <th>Extension</th>\n      <th>Load</th>\n      <th>Pattern</th>\n      <th>Density</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5.09750</td>\n      <td>87.61620</td>\n      <td>2.98682</td>\n      <td>52.56971</td>\n      <td>-5.09750</td>\n      <td>-87.61619</td>\n      <td>CUB</td>\n      <td>80</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20.62094</td>\n      <td>94.02350</td>\n      <td>12.08258</td>\n      <td>56.41410</td>\n      <td>-20.62094</td>\n      <td>-94.02350</td>\n      <td>CUB</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2.57016</td>\n      <td>44.17989</td>\n      <td>1.50595</td>\n      <td>26.50793</td>\n      <td>-2.57016</td>\n      <td>-44.17988</td>\n      <td>OCT</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10.31719</td>\n      <td>72.81451</td>\n      <td>6.04523</td>\n      <td>43.68870</td>\n      <td>-10.31719</td>\n      <td>-72.81451</td>\n      <td>QCU</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3.91109</td>\n      <td>55.16191</td>\n      <td>2.29166</td>\n      <td>33.09715</td>\n      <td>-3.91109</td>\n      <td>-55.16191</td>\n      <td>LIN</td>\n      <td>60</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2027689</th>\n      <td>0.18234</td>\n      <td>0.04409</td>\n      <td>0.10684</td>\n      <td>0.02646</td>\n      <td>-0.18234</td>\n      <td>-0.04409</td>\n      <td>LIN</td>\n      <td>60</td>\n    </tr>\n    <tr>\n      <th>2027690</th>\n      <td>9.14500</td>\n      <td>71.02377</td>\n      <td>5.35840</td>\n      <td>42.61426</td>\n      <td>-9.14500</td>\n      <td>-71.02377</td>\n      <td>CUB</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>2027691</th>\n      <td>4.03016</td>\n      <td>57.97430</td>\n      <td>2.36142</td>\n      <td>34.78458</td>\n      <td>-4.03016</td>\n      <td>-57.97430</td>\n      <td>ZZG</td>\n      <td>60</td>\n    </tr>\n    <tr>\n      <th>2027692</th>\n      <td>2.12766</td>\n      <td>34.03754</td>\n      <td>1.24667</td>\n      <td>20.42252</td>\n      <td>-2.12766</td>\n      <td>-34.03754</td>\n      <td>CUB</td>\n      <td>40</td>\n    </tr>\n    <tr>\n      <th>2027693</th>\n      <td>0.61500</td>\n      <td>6.52319</td>\n      <td>0.36035</td>\n      <td>3.91391</td>\n      <td>-0.61500</td>\n      <td>-6.52319</td>\n      <td>CRS</td>\n      <td>20</td>\n    </tr>\n  </tbody>\n</table>\n<p>2027694 rows × 8 columns</p>\n</div>"},"metadata":{}}],"execution_count":14},{"cell_type":"markdown","source":"## Data Pre-Processing","metadata":{}},{"cell_type":"markdown","source":"### Conversion to float64","metadata":{}},{"cell_type":"code","source":"categorical_cols = ['Pattern']\n\nfor col in df.columns:\n    if col not in categorical_cols:\n        df[col] = pd.to_numeric(df[col], errors='coerce').astype(float)\nprint(df.dtypes)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T16:45:02.051275Z","iopub.execute_input":"2025-08-15T16:45:02.051610Z","iopub.status.idle":"2025-08-15T16:45:07.765293Z","shell.execute_reply.started":"2025-08-15T16:45:02.051570Z","shell.execute_reply":"2025-08-15T16:45:07.764525Z"}},"outputs":[{"name":"stdout","text":"Flexure extension    float64\nFlexure load         float64\nFlexure strain       float64\nFlexure stress       float64\nExtension            float64\nLoad                 float64\nPattern               object\nDensity              float64\ndtype: object\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"### Checking for null values","metadata":{}},{"cell_type":"code","source":"df.isna().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T16:45:07.766138Z","iopub.execute_input":"2025-08-15T16:45:07.766432Z","iopub.status.idle":"2025-08-15T16:45:07.929102Z","shell.execute_reply.started":"2025-08-15T16:45:07.766399Z","shell.execute_reply":"2025-08-15T16:45:07.928276Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"Flexure extension    0\nFlexure load         0\nFlexure strain       0\nFlexure stress       0\nExtension            0\nLoad                 0\nPattern              0\nDensity              0\ndtype: int64"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"df.nunique()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T16:45:07.930163Z","iopub.execute_input":"2025-08-15T16:45:07.930454Z","iopub.status.idle":"2025-08-15T16:45:08.995708Z","shell.execute_reply.started":"2025-08-15T16:45:07.930432Z","shell.execute_reply":"2025-08-15T16:45:08.994876Z"}},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"Flexure extension      86892\nFlexure load         1720570\nFlexure strain         86892\nFlexure stress       1612720\nExtension              86892\nLoad                 1746135\nPattern                   14\nDensity                    5\ndtype: int64"},"metadata":{}}],"execution_count":17},{"cell_type":"markdown","source":"### Outlier detection","metadata":{}},{"cell_type":"code","source":"numeric_cols = [\n    \"Flexure extension\",\n    \"Flexure load\",\n    \"Flexure strain\",\n    \"Flexure stress\",\n    \"Extension\",\n    \"Load\",\n    \"Density\"\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T16:45:08.996736Z","iopub.execute_input":"2025-08-15T16:45:08.997094Z","iopub.status.idle":"2025-08-15T16:45:09.001948Z","shell.execute_reply.started":"2025-08-15T16:45:08.997031Z","shell.execute_reply":"2025-08-15T16:45:09.001077Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"outlier_counts = []\n\nfor col in numeric_cols:\n    for pattern_val, group in df.groupby('Pattern'):\n        Q1 = group[col].quantile(0.25)\n        Q3 = group[col].quantile(0.75)\n        IQR = Q3 - Q1\n        \n        outliers = (group[col] < (Q1 - 1.5 * IQR)) | (group[col] > (Q3 + 1.5 * IQR))\n        \n        total_entries = group[col].notna().sum()\n        count_outliers = outliers.sum()\n        percentage_outliers = (count_outliers / total_entries) * 100\n        \n        outlier_counts.append([col, pattern_val, count_outliers, total_entries, percentage_outliers])\n\noutlier_counts_df = pd.DataFrame(\n    outlier_counts,\n    columns=['Column', 'Pattern', 'Outlier Count', 'Total Entries', 'Outlier %']\n)\n\nprint(outlier_counts_df)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T16:45:09.003086Z","iopub.execute_input":"2025-08-15T16:45:09.003607Z","iopub.status.idle":"2025-08-15T16:45:12.761433Z","shell.execute_reply.started":"2025-08-15T16:45:09.003575Z","shell.execute_reply":"2025-08-15T16:45:12.760449Z"}},"outputs":[{"name":"stdout","text":"               Column Pattern  Outlier Count  Total Entries  Outlier %\n0   Flexure extension     C3D              0         116152   0.000000\n1   Flexure extension     CON              0         145129   0.000000\n2   Flexure extension     CRS           1201         129306   0.928805\n3   Flexure extension     CSD              0         147876   0.000000\n4   Flexure extension     CUB           5522         150828   3.661124\n..                ...     ...            ...            ...        ...\n93            Density     OCT              0         154391   0.000000\n94            Density     QCU              0         156037   0.000000\n95            Density     THX              0         150460   0.000000\n96            Density     TRI              0         147668   0.000000\n97            Density     ZZG              0         168006   0.000000\n\n[98 rows x 5 columns]\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"outlier_counts = []\n\n# Boolean mask to mark rows that have any outlier\noutlier_mask = pd.Series(False, index=df.index)\n\nfor col in numeric_cols:\n    for pattern_val, group in df.groupby('Pattern'):\n        Q1 = group[col].quantile(0.25)\n        Q3 = group[col].quantile(0.75)\n        IQR = Q3 - Q1\n        \n        outliers = (group[col] < (Q1 - 1.5 * IQR)) | (group[col] > (Q3 + 1.5 * IQR))\n        \n        total_entries = group[col].notna().sum()\n        count_outliers = outliers.sum()\n        percentage_outliers = (count_outliers / total_entries) * 100\n        \n        outlier_counts.append([col, pattern_val, count_outliers, total_entries, percentage_outliers])\n        \n        # Mark these outliers in the global mask\n        outlier_mask.loc[outliers.index] |= outliers\n\n# Create the outlier counts DataFrame\noutlier_counts_df = pd.DataFrame(\n    outlier_counts,\n    columns=['Column', 'Pattern', 'Outlier Count', 'Total Entries', 'Outlier %']\n)\n\n# Remove rows with at least one outlier\ndf_cleaned = df.loc[~outlier_mask].copy()\n\nprint(outlier_counts_df)\nprint(f\"Original rows: {len(df)}, Cleaned rows: {len(df_cleaned)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T16:45:12.762346Z","iopub.execute_input":"2025-08-15T16:45:12.762617Z","iopub.status.idle":"2025-08-15T16:45:18.437973Z","shell.execute_reply.started":"2025-08-15T16:45:12.762588Z","shell.execute_reply":"2025-08-15T16:45:18.437069Z"}},"outputs":[{"name":"stdout","text":"               Column Pattern  Outlier Count  Total Entries  Outlier %\n0   Flexure extension     C3D              0         116152   0.000000\n1   Flexure extension     CON              0         145129   0.000000\n2   Flexure extension     CRS           1201         129306   0.928805\n3   Flexure extension     CSD              0         147876   0.000000\n4   Flexure extension     CUB           5522         150828   3.661124\n..                ...     ...            ...            ...        ...\n93            Density     OCT              0         154391   0.000000\n94            Density     QCU              0         156037   0.000000\n95            Density     THX              0         150460   0.000000\n96            Density     TRI              0         147668   0.000000\n97            Density     ZZG              0         168006   0.000000\n\n[98 rows x 5 columns]\nOriginal rows: 2027694, Cleaned rows: 2010673\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T16:45:18.438766Z","iopub.execute_input":"2025-08-15T16:45:18.438982Z","iopub.status.idle":"2025-08-15T16:45:18.444956Z","shell.execute_reply.started":"2025-08-15T16:45:18.438964Z","shell.execute_reply":"2025-08-15T16:45:18.444115Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"(2027694, 8)"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"outlier_df.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T16:45:18.446040Z","iopub.execute_input":"2025-08-15T16:45:18.446339Z","iopub.status.idle":"2025-08-15T16:45:18.558150Z","shell.execute_reply.started":"2025-08-15T16:45:18.446319Z","shell.execute_reply":"2025-08-15T16:45:18.556400Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/213946672.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutlier_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'outlier_df' is not defined"],"ename":"NameError","evalue":"name 'outlier_df' is not defined","output_type":"error"}],"execution_count":22},{"cell_type":"code","source":"df_cleaned.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T16:45:49.391879Z","iopub.execute_input":"2025-08-15T16:45:49.392207Z","iopub.status.idle":"2025-08-15T16:45:49.398546Z","shell.execute_reply.started":"2025-08-15T16:45:49.392181Z","shell.execute_reply":"2025-08-15T16:45:49.397515Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"(2010673, 8)"},"metadata":{}}],"execution_count":23},{"cell_type":"markdown","source":"### Printing some of the outlier rows","metadata":{}},{"cell_type":"code","source":"df_cleaned","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T16:45:54.138764Z","iopub.execute_input":"2025-08-15T16:45:54.139192Z","iopub.status.idle":"2025-08-15T16:45:54.160534Z","shell.execute_reply.started":"2025-08-15T16:45:54.139157Z","shell.execute_reply":"2025-08-15T16:45:54.159513Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"         Flexure extension  Flexure load  Flexure strain  Flexure stress  \\\n0                  5.09750      87.61620         2.98682        52.56971   \n2                  2.57016      44.17989         1.50595        26.50793   \n3                 10.31719      72.81451         6.04523        43.68870   \n4                  3.91109      55.16191         2.29166        33.09715   \n5                 11.40891      64.92645         6.68491        38.95587   \n...                    ...           ...             ...             ...   \n2027689            0.18234       0.04409         0.10684         0.02646   \n2027690            9.14500      71.02377         5.35840        42.61426   \n2027691            4.03016      57.97430         2.36142        34.78458   \n2027692            2.12766      34.03754         1.24667        20.42252   \n2027693            0.61500       6.52319         0.36035         3.91391   \n\n         Extension      Load Pattern  Density  \n0         -5.09750 -87.61619     CUB     80.0  \n2         -2.57016 -44.17988     OCT    100.0  \n3        -10.31719 -72.81451     QCU     20.0  \n4         -3.91109 -55.16191     LIN     60.0  \n5        -11.40891 -64.92645     CRS     20.0  \n...            ...       ...     ...      ...  \n2027689   -0.18234  -0.04409     LIN     60.0  \n2027690   -9.14500 -71.02377     CUB     20.0  \n2027691   -4.03016 -57.97430     ZZG     60.0  \n2027692   -2.12766 -34.03754     CUB     40.0  \n2027693   -0.61500  -6.52319     CRS     20.0  \n\n[2010673 rows x 8 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Flexure extension</th>\n      <th>Flexure load</th>\n      <th>Flexure strain</th>\n      <th>Flexure stress</th>\n      <th>Extension</th>\n      <th>Load</th>\n      <th>Pattern</th>\n      <th>Density</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5.09750</td>\n      <td>87.61620</td>\n      <td>2.98682</td>\n      <td>52.56971</td>\n      <td>-5.09750</td>\n      <td>-87.61619</td>\n      <td>CUB</td>\n      <td>80.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2.57016</td>\n      <td>44.17989</td>\n      <td>1.50595</td>\n      <td>26.50793</td>\n      <td>-2.57016</td>\n      <td>-44.17988</td>\n      <td>OCT</td>\n      <td>100.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10.31719</td>\n      <td>72.81451</td>\n      <td>6.04523</td>\n      <td>43.68870</td>\n      <td>-10.31719</td>\n      <td>-72.81451</td>\n      <td>QCU</td>\n      <td>20.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3.91109</td>\n      <td>55.16191</td>\n      <td>2.29166</td>\n      <td>33.09715</td>\n      <td>-3.91109</td>\n      <td>-55.16191</td>\n      <td>LIN</td>\n      <td>60.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>11.40891</td>\n      <td>64.92645</td>\n      <td>6.68491</td>\n      <td>38.95587</td>\n      <td>-11.40891</td>\n      <td>-64.92645</td>\n      <td>CRS</td>\n      <td>20.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2027689</th>\n      <td>0.18234</td>\n      <td>0.04409</td>\n      <td>0.10684</td>\n      <td>0.02646</td>\n      <td>-0.18234</td>\n      <td>-0.04409</td>\n      <td>LIN</td>\n      <td>60.0</td>\n    </tr>\n    <tr>\n      <th>2027690</th>\n      <td>9.14500</td>\n      <td>71.02377</td>\n      <td>5.35840</td>\n      <td>42.61426</td>\n      <td>-9.14500</td>\n      <td>-71.02377</td>\n      <td>CUB</td>\n      <td>20.0</td>\n    </tr>\n    <tr>\n      <th>2027691</th>\n      <td>4.03016</td>\n      <td>57.97430</td>\n      <td>2.36142</td>\n      <td>34.78458</td>\n      <td>-4.03016</td>\n      <td>-57.97430</td>\n      <td>ZZG</td>\n      <td>60.0</td>\n    </tr>\n    <tr>\n      <th>2027692</th>\n      <td>2.12766</td>\n      <td>34.03754</td>\n      <td>1.24667</td>\n      <td>20.42252</td>\n      <td>-2.12766</td>\n      <td>-34.03754</td>\n      <td>CUB</td>\n      <td>40.0</td>\n    </tr>\n    <tr>\n      <th>2027693</th>\n      <td>0.61500</td>\n      <td>6.52319</td>\n      <td>0.36035</td>\n      <td>3.91391</td>\n      <td>-0.61500</td>\n      <td>-6.52319</td>\n      <td>CRS</td>\n      <td>20.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>2010673 rows × 8 columns</p>\n</div>"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"## Class balancing based on pattern\nprint(\"Rows per pattern:\")\nprint(df['Pattern'].value_counts())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T16:45:54.499185Z","iopub.execute_input":"2025-08-15T16:45:54.499510Z","iopub.status.idle":"2025-08-15T16:45:54.664215Z","shell.execute_reply.started":"2025-08-15T16:45:54.499485Z","shell.execute_reply":"2025-08-15T16:45:54.663197Z"}},"outputs":[{"name":"stdout","text":"Rows per pattern:\nPattern\nZZG    168006\nLIN    156334\nQCU    156037\nOCT    154391\nLIG    151069\nCUB    150828\nTHX    150460\nCSD    147876\nTRI    147668\nCON    145129\nCRS    129306\nGYR    128377\nGRI    126061\nC3D    116152\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":25},{"cell_type":"markdown","source":"## Balancing the dataframe","metadata":{}},{"cell_type":"code","source":"from sklearn.utils import resample\n\n# Find the minimum class count in df_cleaned\nmin_count = df_cleaned['Pattern'].value_counts().min()\n\n# Create a balanced dataframe by downsampling each pattern\nbalanced_df_list = []\nfor pattern_val, group in df_cleaned.groupby('Pattern'):\n    balanced_group = resample(group, \n                              replace=False,  # no duplicate rows\n                              n_samples=min_count, \n                              random_state=42)\n    balanced_df_list.append(balanced_group)\n\n# Combine all into one DataFrame\ndf_balanced = pd.concat(balanced_df_list)\n\n# Shuffle the rows (optional but good practice)\ndf_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n\nprint(df_balanced['Pattern'].value_counts())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T16:45:58.356019Z","iopub.execute_input":"2025-08-15T16:45:58.356325Z","iopub.status.idle":"2025-08-15T16:46:00.334313Z","shell.execute_reply.started":"2025-08-15T16:45:58.356301Z","shell.execute_reply":"2025-08-15T16:46:00.333451Z"}},"outputs":[{"name":"stdout","text":"Pattern\nC3D    116152\nGRI    116152\nLIN    116152\nZZG    116152\nCON    116152\nGYR    116152\nQCU    116152\nTRI    116152\nCRS    116152\nOCT    116152\nCUB    116152\nLIG    116152\nTHX    116152\nCSD    116152\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"df_balanced.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T16:46:02.553341Z","iopub.execute_input":"2025-08-15T16:46:02.554337Z","iopub.status.idle":"2025-08-15T16:46:02.559787Z","shell.execute_reply.started":"2025-08-15T16:46:02.554305Z","shell.execute_reply":"2025-08-15T16:46:02.558902Z"}},"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"(1626128, 8)"},"metadata":{}}],"execution_count":27},{"cell_type":"markdown","source":"## Model Training","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\nle = LabelEncoder()\ndf_balanced['Pattern'] = le.fit_transform(df_balanced['Pattern'])\nscaler = StandardScaler()\ndf_balanced[numeric_cols] = scaler.fit_transform(df_balanced[numeric_cols])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T17:47:14.875391Z","iopub.execute_input":"2025-08-15T17:47:14.877205Z","iopub.status.idle":"2025-08-15T17:47:15.349471Z","shell.execute_reply.started":"2025-08-15T17:47:14.877122Z","shell.execute_reply":"2025-08-15T17:47:15.348564Z"}},"outputs":[],"execution_count":39},{"cell_type":"markdown","source":"## Balanced dataset","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX = df_balanced.drop('Pattern', axis=1)\ny = df_balanced['Pattern']\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, stratify=y, random_state=42\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T17:47:16.794097Z","iopub.execute_input":"2025-08-15T17:47:16.794417Z","iopub.status.idle":"2025-08-15T17:47:17.828186Z","shell.execute_reply.started":"2025-08-15T17:47:16.794389Z","shell.execute_reply":"2025-08-15T17:47:17.827113Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"print(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T17:47:32.308600Z","iopub.execute_input":"2025-08-15T17:47:32.308890Z","iopub.status.idle":"2025-08-15T17:47:32.314108Z","shell.execute_reply.started":"2025-08-15T17:47:32.308862Z","shell.execute_reply":"2025-08-15T17:47:32.313120Z"}},"outputs":[{"name":"stdout","text":"(1300902, 7)\n(325226, 7)\n(1300902,)\n(325226,)\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"from sklearn.metrics import classification_report, accuracy_score\n\n# Import all the models\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nimport xgboost as xgb","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T17:47:19.462746Z","iopub.execute_input":"2025-08-15T17:47:19.463128Z","iopub.status.idle":"2025-08-15T17:47:19.469142Z","shell.execute_reply.started":"2025-08-15T17:47:19.463103Z","shell.execute_reply":"2025-08-15T17:47:19.468130Z"}},"outputs":[],"execution_count":42},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.gaussian_process.kernels import RBF\n\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom tqdm import trange, tqdm\n\nfrom xgboost import XGBClassifier\n\n# Example dataset (replace with your own)\n# from sklearn.datasets import load_iris\n# from sklearn.model_selection import train_test_split\n# X, y = load_iris(return_X_y=True)\n# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n# Define models\nmodels = {\n    \"Random Forest\": RandomForestClassifier(\n        n_estimators=50,\n        warm_start=True,\n        random_state=42\n    ),\n    \n    \n    \"XGBoost\": XGBClassifier(\n        n_estimators=50,\n        learning_rate=0.1,\n        max_depth=6,\n        random_state=42,\n        use_label_encoder=False,\n        eval_metric='mlogloss'\n    ),\n\n    \"K-Nearest Neighbors\": KNeighborsClassifier(\n        n_neighbors=30,\n        weights='distance',\n        metric='euclidean'\n    ),\n    \n    \"Decision Tree\": DecisionTreeClassifier(\n        random_state=42\n    ),\n    \n    \"Extra Trees\": ExtraTreesClassifier(\n        n_estimators=10,\n        random_state=42\n    )\n}\n\n# Training loop\nfor name, model in tqdm(models.items(), desc=\"Training models\"):\n    print(f\"\\n--- {name} ---\")\n    \n    # Incremental fitting for models with n_estimators\n    if hasattr(model, \"n_estimators\"):\n        n_estimators = model.n_estimators\n        for i in trange(1, n_estimators + 1, desc=f\"Training {name}\"):\n            model.set_params(n_estimators=i)\n            model.fit(X_train, y_train)\n    else:\n        for _ in trange(1, 2, desc=f\"Training {name}\"):\n            model.fit(X_train, y_train)\n    \n    # Predict and evaluate\n    y_pred = model.predict(X_test)\n    print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n    print(\"\\nClassification Report:\")\n    print(classification_report(y_test, y_pred))\n    print(\"=\"*40 + \"\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T17:47:50.473853Z","iopub.execute_input":"2025-08-15T17:47:50.474160Z","iopub.status.idle":"2025-08-15T18:18:28.928921Z","shell.execute_reply.started":"2025-08-15T17:47:50.474141Z","shell.execute_reply":"2025-08-15T18:18:28.928055Z"}},"outputs":[{"name":"stderr","text":"Training models:   0%|          | 0/5 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"\n--- Random Forest ---\n","output_type":"stream"},{"name":"stderr","text":"\nTraining Random Forest:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\nTraining Random Forest:   2%|▏         | 1/50 [00:07<06:10,  7.57s/it]\u001b[A\nTraining Random Forest:   4%|▍         | 2/50 [00:15<06:00,  7.51s/it]\u001b[A\nTraining Random Forest:   6%|▌         | 3/50 [00:22<05:54,  7.55s/it]\u001b[A\nTraining Random Forest:   8%|▊         | 4/50 [00:30<05:44,  7.49s/it]\u001b[A\nTraining Random Forest:  10%|█         | 5/50 [00:37<05:36,  7.47s/it]\u001b[A\nTraining Random Forest:  12%|█▏        | 6/50 [00:45<05:40,  7.75s/it]\u001b[A\nTraining Random Forest:  14%|█▍        | 7/50 [00:53<05:37,  7.84s/it]\u001b[A\nTraining Random Forest:  16%|█▌        | 8/50 [01:01<05:33,  7.95s/it]\u001b[A\nTraining Random Forest:  18%|█▊        | 9/50 [01:10<05:27,  7.99s/it]\u001b[A\nTraining Random Forest:  20%|██        | 10/50 [01:18<05:22,  8.05s/it]\u001b[A\nTraining Random Forest:  22%|██▏       | 11/50 [01:26<05:18,  8.17s/it]\u001b[A\nTraining Random Forest:  24%|██▍       | 12/50 [01:35<05:15,  8.31s/it]\u001b[A\nTraining Random Forest:  26%|██▌       | 13/50 [01:43<05:07,  8.30s/it]\u001b[A\nTraining Random Forest:  28%|██▊       | 14/50 [01:52<05:01,  8.37s/it]\u001b[A\nTraining Random Forest:  30%|███       | 15/50 [02:03<05:28,  9.38s/it]\u001b[A\nTraining Random Forest:  32%|███▏      | 16/50 [02:17<06:01, 10.64s/it]\u001b[A\nTraining Random Forest:  34%|███▍      | 17/50 [02:25<05:29,  9.99s/it]\u001b[A\nTraining Random Forest:  36%|███▌      | 18/50 [02:34<05:06,  9.58s/it]\u001b[A\nTraining Random Forest:  38%|███▊      | 19/50 [02:42<04:43,  9.15s/it]\u001b[A\nTraining Random Forest:  40%|████      | 20/50 [02:51<04:27,  8.92s/it]\u001b[A\nTraining Random Forest:  42%|████▏     | 21/50 [02:59<04:14,  8.78s/it]\u001b[A\nTraining Random Forest:  44%|████▍     | 22/50 [03:08<04:04,  8.75s/it]\u001b[A\nTraining Random Forest:  46%|████▌     | 23/50 [03:17<03:57,  8.80s/it]\u001b[A\nTraining Random Forest:  48%|████▊     | 24/50 [03:25<03:44,  8.62s/it]\u001b[A\nTraining Random Forest:  50%|█████     | 25/50 [03:33<03:33,  8.55s/it]\u001b[A\nTraining Random Forest:  52%|█████▏    | 26/50 [03:41<03:21,  8.41s/it]\u001b[A\nTraining Random Forest:  54%|█████▍    | 27/50 [03:50<03:13,  8.40s/it]\u001b[A\nTraining Random Forest:  56%|█████▌    | 28/50 [03:58<03:06,  8.49s/it]\u001b[A\nTraining Random Forest:  58%|█████▊    | 29/50 [04:07<02:58,  8.48s/it]\u001b[A\nTraining Random Forest:  60%|██████    | 30/50 [04:15<02:46,  8.33s/it]\u001b[A\nTraining Random Forest:  62%|██████▏   | 31/50 [04:23<02:38,  8.32s/it]\u001b[A\nTraining Random Forest:  64%|██████▍   | 32/50 [04:32<02:30,  8.36s/it]\u001b[A\nTraining Random Forest:  66%|██████▌   | 33/50 [04:40<02:23,  8.42s/it]\u001b[A\nTraining Random Forest:  68%|██████▊   | 34/50 [04:49<02:14,  8.43s/it]\u001b[A\nTraining Random Forest:  70%|███████   | 35/50 [04:56<02:03,  8.22s/it]\u001b[A\nTraining Random Forest:  72%|███████▏  | 36/50 [05:04<01:53,  8.13s/it]\u001b[A\nTraining Random Forest:  74%|███████▍  | 37/50 [05:12<01:44,  8.01s/it]\u001b[A\nTraining Random Forest:  76%|███████▌  | 38/50 [05:21<01:38,  8.20s/it]\u001b[A\nTraining Random Forest:  78%|███████▊  | 39/50 [05:29<01:29,  8.12s/it]\u001b[A\nTraining Random Forest:  80%|████████  | 40/50 [05:37<01:22,  8.20s/it]\u001b[A\nTraining Random Forest:  82%|████████▏ | 41/50 [05:45<01:12,  8.06s/it]\u001b[A\nTraining Random Forest:  84%|████████▍ | 42/50 [05:53<01:04,  8.02s/it]\u001b[A\nTraining Random Forest:  86%|████████▌ | 43/50 [06:00<00:55,  7.98s/it]\u001b[A\nTraining Random Forest:  88%|████████▊ | 44/50 [06:08<00:47,  7.94s/it]\u001b[A\nTraining Random Forest:  90%|█████████ | 45/50 [06:16<00:39,  7.88s/it]\u001b[A\nTraining Random Forest:  92%|█████████▏| 46/50 [06:23<00:30,  7.73s/it]\u001b[A\nTraining Random Forest:  94%|█████████▍| 47/50 [06:31<00:23,  7.69s/it]\u001b[A\nTraining Random Forest:  96%|█████████▌| 48/50 [06:38<00:15,  7.63s/it]\u001b[A\nTraining Random Forest:  98%|█████████▊| 49/50 [06:46<00:07,  7.71s/it]\u001b[A\nTraining Random Forest: 100%|██████████| 50/50 [06:54<00:00,  8.30s/it]\u001b[A\n","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.8238\n\nClassification Report:\n","output_type":"stream"},{"name":"stderr","text":"Training models:  20%|██        | 1/5 [07:07<28:30, 427.64s/it]","output_type":"stream"},{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.83      0.86      0.85     23230\n           1       0.84      0.84      0.84     23230\n           2       0.80      0.83      0.81     23230\n           3       0.78      0.79      0.78     23231\n           4       0.82      0.81      0.81     23231\n           5       0.82      0.84      0.83     23230\n           6       0.80      0.81      0.81     23231\n           7       0.90      0.90      0.90     23231\n           8       0.85      0.84      0.84     23230\n           9       0.82      0.81      0.81     23230\n          10       0.81      0.79      0.80     23231\n          11       0.82      0.81      0.81     23230\n          12       0.82      0.80      0.81     23230\n          13       0.83      0.81      0.82     23231\n\n    accuracy                           0.82    325226\n   macro avg       0.82      0.82      0.82    325226\nweighted avg       0.82      0.82      0.82    325226\n\n========================================\n\n\n--- XGBoost ---\n","output_type":"stream"},{"name":"stderr","text":"\nTraining XGBoost:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\nTraining XGBoost:   2%|▏         | 1/50 [00:02<01:46,  2.17s/it]\u001b[A\nTraining XGBoost:   4%|▍         | 2/50 [00:05<02:09,  2.69s/it]\u001b[A\nTraining XGBoost:   6%|▌         | 3/50 [00:09<02:31,  3.23s/it]\u001b[A\nTraining XGBoost:   8%|▊         | 4/50 [00:13<02:57,  3.85s/it]\u001b[A\nTraining XGBoost:  10%|█         | 5/50 [00:19<03:24,  4.54s/it]\u001b[A\nTraining XGBoost:  12%|█▏        | 6/50 [00:26<03:51,  5.26s/it]\u001b[A\nTraining XGBoost:  14%|█▍        | 7/50 [00:33<04:17,  5.98s/it]\u001b[A\nTraining XGBoost:  16%|█▌        | 8/50 [00:42<04:43,  6.76s/it]\u001b[A\nTraining XGBoost:  18%|█▊        | 9/50 [00:51<05:10,  7.56s/it]\u001b[A\nTraining XGBoost:  20%|██        | 10/50 [01:01<05:35,  8.39s/it]\u001b[A\nTraining XGBoost:  22%|██▏       | 11/50 [01:12<06:00,  9.23s/it]\u001b[A\nTraining XGBoost:  24%|██▍       | 12/50 [01:25<06:23, 10.10s/it]\u001b[A\nTraining XGBoost:  26%|██▌       | 13/50 [01:37<06:44, 10.94s/it]\u001b[A\nTraining XGBoost:  28%|██▊       | 14/50 [01:51<07:04, 11.78s/it]\u001b[A\nTraining XGBoost:  30%|███       | 15/50 [02:06<07:23, 12.67s/it]\u001b[A\nTraining XGBoost:  32%|███▏      | 16/50 [02:21<07:40, 13.56s/it]\u001b[A\nTraining XGBoost:  34%|███▍      | 17/50 [02:38<07:55, 14.42s/it]\u001b[A\nTraining XGBoost:  36%|███▌      | 18/50 [02:55<08:11, 15.36s/it]\u001b[A\nTraining XGBoost:  38%|███▊      | 19/50 [03:14<08:23, 16.23s/it]\u001b[A\nTraining XGBoost:  40%|████      | 20/50 [03:33<08:32, 17.10s/it]\u001b[A\nTraining XGBoost:  42%|████▏     | 21/50 [03:53<08:42, 18.00s/it]\u001b[A\nTraining XGBoost:  44%|████▍     | 22/50 [04:14<08:49, 18.90s/it]\u001b[A\nTraining XGBoost:  46%|████▌     | 23/50 [04:36<08:55, 19.83s/it]\u001b[A\nTraining XGBoost:  48%|████▊     | 24/50 [04:59<08:58, 20.72s/it]\u001b[A\nTraining XGBoost:  50%|█████     | 25/50 [05:23<09:04, 21.76s/it]\u001b[A\nTraining XGBoost:  52%|█████▏    | 26/50 [05:48<09:04, 22.70s/it]\u001b[A\nTraining XGBoost:  54%|█████▍    | 27/50 [06:14<09:04, 23.67s/it]\u001b[A\nTraining XGBoost:  56%|█████▌    | 28/50 [06:41<09:02, 24.64s/it]\u001b[A\nTraining XGBoost:  58%|█████▊    | 29/50 [07:08<08:57, 25.60s/it]\u001b[A\nTraining XGBoost:  60%|██████    | 30/50 [07:38<08:53, 26.67s/it]\u001b[A\nTraining XGBoost:  62%|██████▏   | 31/50 [08:07<08:43, 27.53s/it]\u001b[A\nTraining XGBoost:  64%|██████▍   | 32/50 [08:38<08:31, 28.40s/it]\u001b[A\nTraining XGBoost:  66%|██████▌   | 33/50 [09:10<08:20, 29.45s/it]\u001b[A\nTraining XGBoost:  68%|██████▊   | 34/50 [09:42<08:05, 30.33s/it]\u001b[A\nTraining XGBoost:  70%|███████   | 35/50 [10:15<07:47, 31.18s/it]\u001b[A\nTraining XGBoost:  72%|███████▏  | 36/50 [10:49<07:28, 32.01s/it]\u001b[A\nTraining XGBoost:  74%|███████▍  | 37/50 [11:25<07:09, 33.07s/it]\u001b[A\nTraining XGBoost:  76%|███████▌  | 38/50 [12:01<06:50, 34.17s/it]\u001b[A\nTraining XGBoost:  78%|███████▊  | 39/50 [12:38<06:25, 35.05s/it]\u001b[A\nTraining XGBoost:  80%|████████  | 40/50 [13:16<05:57, 35.79s/it]\u001b[A\nTraining XGBoost:  82%|████████▏ | 41/50 [13:55<05:30, 36.69s/it]\u001b[A\nTraining XGBoost:  84%|████████▍ | 42/50 [14:35<05:01, 37.63s/it]\u001b[A\nTraining XGBoost:  86%|████████▌ | 43/50 [15:15<04:29, 38.56s/it]\u001b[A\nTraining XGBoost:  88%|████████▊ | 44/50 [15:57<03:57, 39.59s/it]\u001b[A\nTraining XGBoost:  90%|█████████ | 45/50 [16:39<03:21, 40.37s/it]\u001b[A\nTraining XGBoost:  92%|█████████▏| 46/50 [17:22<02:44, 41.15s/it]\u001b[A\nTraining XGBoost:  94%|█████████▍| 47/50 [18:06<02:05, 41.88s/it]\u001b[A\nTraining XGBoost:  96%|█████████▌| 48/50 [18:50<01:25, 42.63s/it]\u001b[A\nTraining XGBoost:  98%|█████████▊| 49/50 [19:36<00:43, 43.38s/it]\u001b[A\nTraining XGBoost: 100%|██████████| 50/50 [20:22<00:00, 24.46s/it]\u001b[A\n","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.3550\n\nClassification Report:\n","output_type":"stream"},{"name":"stderr","text":"Training models:  40%|████      | 2/5 [27:33<44:51, 897.21s/it]","output_type":"stream"},{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.19      0.80      0.31     23230\n           1       0.75      0.51      0.61     23230\n           2       0.33      0.42      0.37     23230\n           3       0.41      0.21      0.28     23231\n           4       0.54      0.23      0.32     23231\n           5       0.29      0.46      0.35     23230\n           6       0.28      0.22      0.25     23231\n           7       0.51      0.66      0.57     23231\n           8       0.58      0.26      0.36     23230\n           9       0.45      0.27      0.33     23230\n          10       0.43      0.22      0.29     23231\n          11       0.34      0.26      0.30     23230\n          12       0.37      0.27      0.31     23230\n          13       0.61      0.19      0.29     23231\n\n    accuracy                           0.35    325226\n   macro avg       0.44      0.35      0.35    325226\nweighted avg       0.44      0.35      0.35    325226\n\n========================================\n\n\n--- K-Nearest Neighbors ---\n","output_type":"stream"},{"name":"stderr","text":"\nTraining K-Nearest Neighbors:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\nTraining K-Nearest Neighbors: 100%|██████████| 1/1 [00:04<00:00,  4.58s/it]\u001b[A\n","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.8200\n\nClassification Report:\n","output_type":"stream"},{"name":"stderr","text":"Training models:  60%|██████    | 3/5 [28:04<16:43, 501.76s/it]","output_type":"stream"},{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.81      0.89      0.85     23230\n           1       0.87      0.83      0.85     23230\n           2       0.77      0.87      0.82     23230\n           3       0.79      0.77      0.78     23231\n           4       0.83      0.79      0.81     23231\n           5       0.80      0.86      0.83     23230\n           6       0.78      0.82      0.80     23231\n           7       0.90      0.90      0.90     23231\n           8       0.85      0.82      0.84     23230\n           9       0.83      0.79      0.81     23230\n          10       0.81      0.77      0.79     23231\n          11       0.80      0.80      0.80     23230\n          12       0.82      0.79      0.81     23230\n          13       0.84      0.77      0.81     23231\n\n    accuracy                           0.82    325226\n   macro avg       0.82      0.82      0.82    325226\nweighted avg       0.82      0.82      0.82    325226\n\n========================================\n\n\n--- Decision Tree ---\n","output_type":"stream"},{"name":"stderr","text":"\nTraining Decision Tree:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\nTraining Decision Tree: 100%|██████████| 1/1 [00:33<00:00, 33.31s/it]\u001b[A\n","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.7868\n\nClassification Report:\n","output_type":"stream"},{"name":"stderr","text":"Training models:  80%|████████  | 4/5 [28:38<05:17, 317.20s/it]","output_type":"stream"},{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.81      0.82      0.81     23230\n           1       0.82      0.81      0.81     23230\n           2       0.78      0.78      0.78     23230\n           3       0.75      0.75      0.75     23231\n           4       0.77      0.77      0.77     23231\n           5       0.79      0.79      0.79     23230\n           6       0.77      0.76      0.76     23231\n           7       0.87      0.87      0.87     23231\n           8       0.81      0.81      0.81     23230\n           9       0.77      0.76      0.77     23230\n          10       0.76      0.76      0.76     23231\n          11       0.77      0.78      0.78     23230\n          12       0.77      0.77      0.77     23230\n          13       0.78      0.79      0.78     23231\n\n    accuracy                           0.79    325226\n   macro avg       0.79      0.79      0.79    325226\nweighted avg       0.79      0.79      0.79    325226\n\n========================================\n\n\n--- Extra Trees ---\n","output_type":"stream"},{"name":"stderr","text":"\nTraining Extra Trees:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\nTraining Extra Trees:  10%|█         | 1/10 [00:02<00:20,  2.26s/it]\u001b[A\nTraining Extra Trees:  20%|██        | 2/10 [00:06<00:27,  3.50s/it]\u001b[A\nTraining Extra Trees:  30%|███       | 3/10 [00:13<00:33,  4.81s/it]\u001b[A\nTraining Extra Trees:  40%|████      | 4/10 [00:21<00:37,  6.24s/it]\u001b[A\nTraining Extra Trees:  50%|█████     | 5/10 [00:32<00:39,  7.80s/it]\u001b[A\nTraining Extra Trees:  60%|██████    | 6/10 [00:44<00:37,  9.41s/it]\u001b[A\nTraining Extra Trees:  70%|███████   | 7/10 [00:59<00:33, 11.11s/it]\u001b[A\nTraining Extra Trees:  80%|████████  | 8/10 [01:15<00:25, 12.91s/it]\u001b[A\nTraining Extra Trees:  90%|█████████ | 9/10 [01:34<00:14, 14.77s/it]\u001b[A\nTraining Extra Trees: 100%|██████████| 10/10 [01:55<00:00, 11.55s/it]\u001b[A\n","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.8368\n\nClassification Report:\n","output_type":"stream"},{"name":"stderr","text":"Training models: 100%|██████████| 5/5 [30:38<00:00, 367.63s/it]","output_type":"stream"},{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.84      0.87      0.86     23230\n           1       0.85      0.86      0.86     23230\n           2       0.81      0.84      0.83     23230\n           3       0.79      0.81      0.80     23231\n           4       0.83      0.83      0.83     23231\n           5       0.84      0.85      0.84     23230\n           6       0.82      0.82      0.82     23231\n           7       0.91      0.91      0.91     23231\n           8       0.86      0.85      0.85     23230\n           9       0.83      0.82      0.83     23230\n          10       0.82      0.80      0.81     23231\n          11       0.83      0.81      0.82     23230\n          12       0.84      0.81      0.82     23230\n          13       0.85      0.82      0.83     23231\n\n    accuracy                           0.84    325226\n   macro avg       0.84      0.84      0.84    325226\nweighted avg       0.84      0.84      0.84    325226\n\n========================================\n\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":44},{"cell_type":"markdown","source":"## Applying PCA","metadata":{}},{"cell_type":"code","source":"df_cleaned1 = df_balanced.copy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T16:46:16.503134Z","iopub.execute_input":"2025-08-15T16:46:16.503494Z","iopub.status.idle":"2025-08-15T16:46:16.627887Z","shell.execute_reply.started":"2025-08-15T16:46:16.503469Z","shell.execute_reply":"2025-08-15T16:46:16.626897Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\n\n# Features for PCA\nflexure_features = ['Flexure extension', 'Flexure load', 'Flexure strain', 'Flexure stress', \"Extension\", \"Load\", \"Density\"]\n\n# 1. Standardize the features\nscaler = StandardScaler()\nflexure_scaled = scaler.fit_transform(df_cleaned1[flexure_features])\n\n# 2. Apply PCA\npca = PCA(n_components=3)\nflexure_pca = pca.fit_transform(flexure_scaled)\n\n# 3. Convert PCA output to a DataFrame\npca_columns = ['Flexure_PC1', 'Flexure_PC2', 'Flexure_PC3']\nflexure_pca_df = pd.DataFrame(flexure_pca, columns=pca_columns, index=df_cleaned1.index)  # <-- add index to align\n\n# 4. Concatenate with the original DataFrame (dropping original Flexure features)\ndf_cleaned1 = pd.concat([df_cleaned1.drop(columns=flexure_features), flexure_pca_df], axis=1)\n\n# Optional: check explained variance\nexplained_variance = pca.explained_variance_ratio_\nprint(\"Explained variance ratio of each PC:\", explained_variance)\nprint(\"Total variance captured by 4 PCs:\", explained_variance.sum())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T16:46:16.858516Z","iopub.execute_input":"2025-08-15T16:46:16.858815Z","iopub.status.idle":"2025-08-15T16:46:19.873860Z","shell.execute_reply.started":"2025-08-15T16:46:16.858792Z","shell.execute_reply":"2025-08-15T16:46:19.872897Z"}},"outputs":[{"name":"stdout","text":"Explained variance ratio of each PC: [0.78689059 0.14986973 0.06323967]\nTotal variance captured by 4 PCs: 0.9999999999997664\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"df_cleaned1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T16:46:19.875372Z","iopub.execute_input":"2025-08-15T16:46:19.875738Z","iopub.status.idle":"2025-08-15T16:46:19.886683Z","shell.execute_reply.started":"2025-08-15T16:46:19.875715Z","shell.execute_reply":"2025-08-15T16:46:19.885805Z"}},"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"         Pattern  Flexure_PC1  Flexure_PC2  Flexure_PC3\n0              0    -3.007116    -0.109848     0.309833\n1              5    -1.949705    -0.247869    -0.284809\n2              0    -4.268158    -1.322789     1.358090\n3              8     1.552107    -1.563248    -0.605415\n4              8    -0.114610    -0.181655    -0.545685\n...          ...          ...          ...          ...\n1626123        2     0.082532    -0.272947    -0.821895\n1626124       12     2.331822    -0.501635    -0.016434\n1626125        1     0.272289    -1.015924    -0.833300\n1626126        5     0.248379    -0.257777    -0.822304\n1626127        1     1.524159     1.475332    -0.562103\n\n[1626128 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pattern</th>\n      <th>Flexure_PC1</th>\n      <th>Flexure_PC2</th>\n      <th>Flexure_PC3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>-3.007116</td>\n      <td>-0.109848</td>\n      <td>0.309833</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5</td>\n      <td>-1.949705</td>\n      <td>-0.247869</td>\n      <td>-0.284809</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>-4.268158</td>\n      <td>-1.322789</td>\n      <td>1.358090</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>8</td>\n      <td>1.552107</td>\n      <td>-1.563248</td>\n      <td>-0.605415</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>8</td>\n      <td>-0.114610</td>\n      <td>-0.181655</td>\n      <td>-0.545685</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1626123</th>\n      <td>2</td>\n      <td>0.082532</td>\n      <td>-0.272947</td>\n      <td>-0.821895</td>\n    </tr>\n    <tr>\n      <th>1626124</th>\n      <td>12</td>\n      <td>2.331822</td>\n      <td>-0.501635</td>\n      <td>-0.016434</td>\n    </tr>\n    <tr>\n      <th>1626125</th>\n      <td>1</td>\n      <td>0.272289</td>\n      <td>-1.015924</td>\n      <td>-0.833300</td>\n    </tr>\n    <tr>\n      <th>1626126</th>\n      <td>5</td>\n      <td>0.248379</td>\n      <td>-0.257777</td>\n      <td>-0.822304</td>\n    </tr>\n    <tr>\n      <th>1626127</th>\n      <td>1</td>\n      <td>1.524159</td>\n      <td>1.475332</td>\n      <td>-0.562103</td>\n    </tr>\n  </tbody>\n</table>\n<p>1626128 rows × 4 columns</p>\n</div>"},"metadata":{}}],"execution_count":31},{"cell_type":"code","source":"# df_cleaned1.drop('Flexure_PC4', axis=1, inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T16:46:19.887593Z","iopub.execute_input":"2025-08-15T16:46:19.887953Z","iopub.status.idle":"2025-08-15T16:46:19.903599Z","shell.execute_reply.started":"2025-08-15T16:46:19.887925Z","shell.execute_reply":"2025-08-15T16:46:19.902536Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\nle = LabelEncoder()\ndf_cleaned1['Pattern'] = le.fit_transform(df_cleaned1['Pattern'])\n# scaler = StandardScaler()\n# df_cleaned1[numeric_cols] = scaler.fit_transform(df_cleaned1[numeric_cols])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T16:46:19.905396Z","iopub.execute_input":"2025-08-15T16:46:19.905724Z","iopub.status.idle":"2025-08-15T16:46:20.060680Z","shell.execute_reply.started":"2025-08-15T16:46:19.905701Z","shell.execute_reply":"2025-08-15T16:46:20.059813Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"df_cleaned1.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T16:46:20.429055Z","iopub.execute_input":"2025-08-15T16:46:20.429396Z","iopub.status.idle":"2025-08-15T16:46:20.439122Z","shell.execute_reply.started":"2025-08-15T16:46:20.429339Z","shell.execute_reply":"2025-08-15T16:46:20.438376Z"}},"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"   Pattern  Flexure_PC1  Flexure_PC2  Flexure_PC3\n0        0    -3.007116    -0.109848     0.309833\n1        5    -1.949705    -0.247869    -0.284809\n2        0    -4.268158    -1.322789     1.358090\n3        8     1.552107    -1.563248    -0.605415\n4        8    -0.114610    -0.181655    -0.545685","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pattern</th>\n      <th>Flexure_PC1</th>\n      <th>Flexure_PC2</th>\n      <th>Flexure_PC3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>-3.007116</td>\n      <td>-0.109848</td>\n      <td>0.309833</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5</td>\n      <td>-1.949705</td>\n      <td>-0.247869</td>\n      <td>-0.284809</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>-4.268158</td>\n      <td>-1.322789</td>\n      <td>1.358090</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>8</td>\n      <td>1.552107</td>\n      <td>-1.563248</td>\n      <td>-0.605415</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>8</td>\n      <td>-0.114610</td>\n      <td>-0.181655</td>\n      <td>-0.545685</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":34},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX = df_cleaned1.drop('Pattern', axis=1)\ny = df_cleaned1['Pattern']\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, stratify=y, random_state=42\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T16:46:23.740847Z","iopub.execute_input":"2025-08-15T16:46:23.741200Z","iopub.status.idle":"2025-08-15T16:46:24.569961Z","shell.execute_reply.started":"2025-08-15T16:46:23.741175Z","shell.execute_reply":"2025-08-15T16:46:24.569164Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"# df_cleaned1= df_cleaned1.drop('Flexure_PC4', axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T16:46:24.623094Z","iopub.execute_input":"2025-08-15T16:46:24.623446Z","iopub.status.idle":"2025-08-15T16:46:24.627577Z","shell.execute_reply.started":"2025-08-15T16:46:24.623422Z","shell.execute_reply":"2025-08-15T16:46:24.626772Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"print(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T16:46:25.478879Z","iopub.execute_input":"2025-08-15T16:46:25.479227Z","iopub.status.idle":"2025-08-15T16:46:25.484891Z","shell.execute_reply.started":"2025-08-15T16:46:25.479202Z","shell.execute_reply":"2025-08-15T16:46:25.483921Z"}},"outputs":[{"name":"stdout","text":"(1300902, 3)\n(325226, 3)\n(1300902,)\n(325226,)\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.gaussian_process.kernels import RBF\n\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom tqdm import trange, tqdm\n\nfrom xgboost import XGBClassifier\n\n# Example dataset (replace with your own)\n# from sklearn.datasets import load_iris\n# from sklearn.model_selection import train_test_split\n# X, y = load_iris(return_X_y=True)\n# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n# Define models\nmodels = {\n    \"Random Forest\": RandomForestClassifier(\n        n_estimators=50,\n        warm_start=True,\n        random_state=42\n    ),\n    \n\n    \"XGBoost\": XGBClassifier(\n        n_estimators=50,\n        learning_rate=0.1,\n        max_depth=6,\n        random_state=42,\n        use_label_encoder=False,\n        eval_metric='mlogloss'\n    ),\n\n    \"K-Nearest Neighbors\": KNeighborsClassifier(\n        n_neighbors=50,\n        weights='distance',\n        metric='euclidean'\n    ),\n    \n    \"Decision Tree\": DecisionTreeClassifier(\n        random_state=42\n    ),\n    \n    \"Extra Trees\": ExtraTreesClassifier(\n        n_estimators=50,\n        random_state=42\n    )\n}\n\n# Training loop\nfor name, model in tqdm(models.items(), desc=\"Training models\"):\n    print(f\"\\n--- {name} ---\")\n    \n    # Incremental fitting for models with n_estimators\n    if hasattr(model, \"n_estimators\"):\n        n_estimators = model.n_estimators\n        for i in trange(1, n_estimators + 1, desc=f\"Training {name}\"):\n            model.set_params(n_estimators=i)\n            model.fit(X_train, y_train)\n    else:\n        for _ in trange(1, 2, desc=f\"Training {name}\"):\n            model.fit(X_train, y_train)\n    \n    # Predict and evaluate\n    y_pred = model.predict(X_test)\n    print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n    print(\"\\nClassification Report:\")\n    print(classification_report(y_test, y_pred))\n    print(\"=\"*40 + \"\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T16:46:29.619640Z","iopub.execute_input":"2025-08-15T16:46:29.619947Z","iopub.status.idle":"2025-08-15T17:43:18.591009Z","shell.execute_reply.started":"2025-08-15T16:46:29.619924Z","shell.execute_reply":"2025-08-15T17:43:18.589413Z"}},"outputs":[{"name":"stderr","text":"Training models:   0%|          | 0/5 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"\n--- Random Forest ---\n","output_type":"stream"},{"name":"stderr","text":"\nTraining Random Forest:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\nTraining Random Forest:   2%|▏         | 1/50 [00:06<04:58,  6.09s/it]\u001b[A\nTraining Random Forest:   4%|▍         | 2/50 [00:12<05:01,  6.28s/it]\u001b[A\nTraining Random Forest:   6%|▌         | 3/50 [00:19<05:01,  6.42s/it]\u001b[A\nTraining Random Forest:   8%|▊         | 4/50 [00:24<04:44,  6.18s/it]\u001b[A\nTraining Random Forest:  10%|█         | 5/50 [00:31<04:51,  6.47s/it]\u001b[A\nTraining Random Forest:  12%|█▏        | 6/50 [00:38<04:39,  6.36s/it]\u001b[A\nTraining Random Forest:  14%|█▍        | 7/50 [00:44<04:30,  6.28s/it]\u001b[A\nTraining Random Forest:  16%|█▌        | 8/50 [00:50<04:22,  6.26s/it]\u001b[A\nTraining Random Forest:  18%|█▊        | 9/50 [00:56<04:13,  6.17s/it]\u001b[A\nTraining Random Forest:  20%|██        | 10/50 [01:03<04:12,  6.32s/it]\u001b[A\nTraining Random Forest:  22%|██▏       | 11/50 [01:09<04:05,  6.29s/it]\u001b[A\nTraining Random Forest:  24%|██▍       | 12/50 [01:15<03:57,  6.26s/it]\u001b[A\nTraining Random Forest:  26%|██▌       | 13/50 [01:21<03:48,  6.18s/it]\u001b[A\nTraining Random Forest:  28%|██▊       | 14/50 [01:28<03:50,  6.39s/it]\u001b[A\nTraining Random Forest:  30%|███       | 15/50 [01:34<03:44,  6.42s/it]\u001b[A\nTraining Random Forest:  32%|███▏      | 16/50 [01:41<03:42,  6.55s/it]\u001b[A\nTraining Random Forest:  34%|███▍      | 17/50 [01:47<03:33,  6.47s/it]\u001b[A\nTraining Random Forest:  36%|███▌      | 18/50 [01:54<03:25,  6.42s/it]\u001b[A\nTraining Random Forest:  38%|███▊      | 19/50 [02:00<03:18,  6.42s/it]\u001b[A\nTraining Random Forest:  40%|████      | 20/50 [02:06<03:12,  6.41s/it]\u001b[A\nTraining Random Forest:  42%|████▏     | 21/50 [02:13<03:08,  6.51s/it]\u001b[A\nTraining Random Forest:  44%|████▍     | 22/50 [02:19<02:58,  6.38s/it]\u001b[A\nTraining Random Forest:  46%|████▌     | 23/50 [02:26<02:53,  6.41s/it]\u001b[A\nTraining Random Forest:  48%|████▊     | 24/50 [02:33<02:49,  6.50s/it]\u001b[A\nTraining Random Forest:  50%|█████     | 25/50 [02:39<02:42,  6.48s/it]\u001b[A\nTraining Random Forest:  52%|█████▏    | 26/50 [02:45<02:35,  6.49s/it]\u001b[A\nTraining Random Forest:  54%|█████▍    | 27/50 [02:52<02:28,  6.44s/it]\u001b[A\nTraining Random Forest:  56%|█████▌    | 28/50 [02:59<02:23,  6.54s/it]\u001b[A\nTraining Random Forest:  58%|█████▊    | 29/50 [03:05<02:16,  6.52s/it]\u001b[A\nTraining Random Forest:  60%|██████    | 30/50 [03:11<02:08,  6.44s/it]\u001b[A\nTraining Random Forest:  62%|██████▏   | 31/50 [03:17<02:00,  6.35s/it]\u001b[A\nTraining Random Forest:  64%|██████▍   | 32/50 [03:24<01:55,  6.39s/it]\u001b[A\nTraining Random Forest:  66%|██████▌   | 33/50 [03:30<01:47,  6.34s/it]\u001b[A\nTraining Random Forest:  68%|██████▊   | 34/50 [03:36<01:41,  6.32s/it]\u001b[A\nTraining Random Forest:  70%|███████   | 35/50 [03:43<01:34,  6.31s/it]\u001b[A\nTraining Random Forest:  72%|███████▏  | 36/50 [03:50<01:30,  6.49s/it]\u001b[A\nTraining Random Forest:  74%|███████▍  | 37/50 [03:55<01:21,  6.30s/it]\u001b[A\nTraining Random Forest:  76%|███████▌  | 38/50 [04:02<01:17,  6.42s/it]\u001b[A\nTraining Random Forest:  78%|███████▊  | 39/50 [04:08<01:09,  6.34s/it]\u001b[A\nTraining Random Forest:  80%|████████  | 40/50 [04:15<01:04,  6.45s/it]\u001b[A\nTraining Random Forest:  82%|████████▏ | 41/50 [04:21<00:57,  6.44s/it]\u001b[A\nTraining Random Forest:  84%|████████▍ | 42/50 [04:28<00:51,  6.47s/it]\u001b[A\nTraining Random Forest:  86%|████████▌ | 43/50 [04:35<00:46,  6.63s/it]\u001b[A\nTraining Random Forest:  88%|████████▊ | 44/50 [04:41<00:39,  6.50s/it]\u001b[A\nTraining Random Forest:  90%|█████████ | 45/50 [04:48<00:32,  6.45s/it]\u001b[A\nTraining Random Forest:  92%|█████████▏| 46/50 [04:54<00:26,  6.58s/it]\u001b[A\nTraining Random Forest:  94%|█████████▍| 47/50 [05:02<00:20,  6.74s/it]\u001b[A\nTraining Random Forest:  96%|█████████▌| 48/50 [05:08<00:13,  6.61s/it]\u001b[A\nTraining Random Forest:  98%|█████████▊| 49/50 [05:14<00:06,  6.57s/it]\u001b[A\nTraining Random Forest: 100%|██████████| 50/50 [05:21<00:00,  6.43s/it]\u001b[A\n","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.8697\n\nClassification Report:\n","output_type":"stream"},{"name":"stderr","text":"Training models:  20%|██        | 1/5 [05:35<22:22, 335.60s/it]","output_type":"stream"},{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.89      0.91      0.90     23230\n           1       0.90      0.90      0.90     23230\n           2       0.86      0.88      0.87     23230\n           3       0.83      0.84      0.83     23231\n           4       0.87      0.87      0.87     23231\n           5       0.87      0.88      0.87     23230\n           6       0.85      0.86      0.85     23231\n           7       0.94      0.94      0.94     23231\n           8       0.88      0.87      0.87     23230\n           9       0.86      0.85      0.85     23230\n          10       0.84      0.83      0.84     23231\n          11       0.85      0.84      0.85     23230\n          12       0.87      0.86      0.86     23230\n          13       0.87      0.85      0.86     23231\n\n    accuracy                           0.87    325226\n   macro avg       0.87      0.87      0.87    325226\nweighted avg       0.87      0.87      0.87    325226\n\n========================================\n\n\n--- XGBoost ---\n","output_type":"stream"},{"name":"stderr","text":"\nTraining XGBoost:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\nTraining XGBoost:   2%|▏         | 1/50 [00:01<01:23,  1.69s/it]\u001b[A\nTraining XGBoost:   4%|▍         | 2/50 [00:04<01:43,  2.16s/it]\u001b[A\nTraining XGBoost:   6%|▌         | 3/50 [00:07<02:08,  2.73s/it]\u001b[A\nTraining XGBoost:   8%|▊         | 4/50 [00:11<02:31,  3.29s/it]\u001b[A\nTraining XGBoost:  10%|█         | 5/50 [00:17<03:03,  4.08s/it]\u001b[A\nTraining XGBoost:  12%|█▏        | 6/50 [00:23<03:31,  4.82s/it]\u001b[A\nTraining XGBoost:  14%|█▍        | 7/50 [00:30<03:55,  5.49s/it]\u001b[A\nTraining XGBoost:  16%|█▌        | 8/50 [00:38<04:19,  6.18s/it]\u001b[A\nTraining XGBoost:  18%|█▊        | 9/50 [00:46<04:44,  6.93s/it]\u001b[A\nTraining XGBoost:  20%|██        | 10/50 [00:55<05:06,  7.67s/it]\u001b[A\nTraining XGBoost:  22%|██▏       | 11/50 [01:06<05:28,  8.43s/it]\u001b[A\nTraining XGBoost:  24%|██▍       | 12/50 [01:17<05:51,  9.25s/it]\u001b[A\nTraining XGBoost:  26%|██▌       | 13/50 [01:28<06:10, 10.01s/it]\u001b[A\nTraining XGBoost:  28%|██▊       | 14/50 [01:41<06:29, 10.81s/it]\u001b[A\nTraining XGBoost:  30%|███       | 15/50 [01:55<06:46, 11.62s/it]\u001b[A\nTraining XGBoost:  32%|███▏      | 16/50 [02:09<07:02, 12.43s/it]\u001b[A\nTraining XGBoost:  34%|███▍      | 17/50 [02:24<07:14, 13.15s/it]\u001b[A\nTraining XGBoost:  36%|███▌      | 18/50 [02:40<07:26, 13.95s/it]\u001b[A\nTraining XGBoost:  38%|███▊      | 19/50 [02:56<07:38, 14.79s/it]\u001b[A\nTraining XGBoost:  40%|████      | 20/50 [03:14<07:49, 15.65s/it]\u001b[A\nTraining XGBoost:  42%|████▏     | 21/50 [03:32<07:57, 16.45s/it]\u001b[A\nTraining XGBoost:  44%|████▍     | 22/50 [03:51<08:03, 17.28s/it]\u001b[A\nTraining XGBoost:  46%|████▌     | 23/50 [04:11<08:08, 18.10s/it]\u001b[A\nTraining XGBoost:  48%|████▊     | 24/50 [04:32<08:11, 18.89s/it]\u001b[A\nTraining XGBoost:  50%|█████     | 25/50 [04:54<08:12, 19.70s/it]\u001b[A\nTraining XGBoost:  52%|█████▏    | 26/50 [05:16<08:11, 20.49s/it]\u001b[A\nTraining XGBoost:  54%|█████▍    | 27/50 [05:39<08:09, 21.27s/it]\u001b[A\nTraining XGBoost:  56%|█████▌    | 28/50 [06:03<08:05, 22.09s/it]\u001b[A\nTraining XGBoost:  58%|█████▊    | 29/50 [06:28<07:59, 22.83s/it]\u001b[A\nTraining XGBoost:  60%|██████    | 30/50 [06:53<07:51, 23.58s/it]\u001b[A\nTraining XGBoost:  62%|██████▏   | 31/50 [07:19<07:42, 24.36s/it]\u001b[A\nTraining XGBoost:  64%|██████▍   | 32/50 [07:46<07:30, 25.05s/it]\u001b[A\nTraining XGBoost:  66%|██████▌   | 33/50 [08:14<07:21, 25.96s/it]\u001b[A\nTraining XGBoost:  68%|██████▊   | 34/50 [08:43<07:08, 26.78s/it]\u001b[A\nTraining XGBoost:  70%|███████   | 35/50 [09:12<06:53, 27.57s/it]\u001b[A\nTraining XGBoost:  72%|███████▏  | 36/50 [09:42<06:36, 28.31s/it]\u001b[A\nTraining XGBoost:  74%|███████▍  | 37/50 [10:13<06:17, 29.04s/it]\u001b[A\nTraining XGBoost:  76%|███████▌  | 38/50 [10:45<06:00, 30.05s/it]\u001b[A\nTraining XGBoost:  78%|███████▊  | 39/50 [11:19<05:41, 31.08s/it]\u001b[A\nTraining XGBoost:  80%|████████  | 40/50 [11:53<05:20, 32.02s/it]\u001b[A\nTraining XGBoost:  82%|████████▏ | 41/50 [12:28<04:55, 32.86s/it]\u001b[A\nTraining XGBoost:  84%|████████▍ | 42/50 [13:03<04:29, 33.64s/it]\u001b[A\nTraining XGBoost:  86%|████████▌ | 43/50 [13:40<04:01, 34.48s/it]\u001b[A\nTraining XGBoost:  88%|████████▊ | 44/50 [14:17<03:32, 35.42s/it]\u001b[A\nTraining XGBoost:  90%|█████████ | 45/50 [14:55<03:00, 36.03s/it]\u001b[A\nTraining XGBoost:  92%|█████████▏| 46/50 [15:33<02:26, 36.68s/it]\u001b[A\nTraining XGBoost:  94%|█████████▍| 47/50 [16:12<01:52, 37.50s/it]\u001b[A\nTraining XGBoost:  96%|█████████▌| 48/50 [16:52<01:16, 38.21s/it]\u001b[A\nTraining XGBoost:  98%|█████████▊| 49/50 [17:33<00:38, 38.88s/it]\u001b[A\nTraining XGBoost: 100%|██████████| 50/50 [18:15<00:00, 21.90s/it]\u001b[A\n","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.3351\n\nClassification Report:\n","output_type":"stream"},{"name":"stderr","text":"Training models:  40%|████      | 2/5 [23:53<39:12, 784.18s/it]","output_type":"stream"},{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.25      0.77      0.38     23230\n           1       0.72      0.57      0.64     23230\n           2       0.34      0.40      0.36     23230\n           3       0.28      0.06      0.10     23231\n           4       0.52      0.22      0.31     23231\n           5       0.30      0.42      0.35     23230\n           6       0.19      0.23      0.21     23231\n           7       0.45      0.64      0.53     23231\n           8       0.34      0.36      0.35     23230\n           9       0.30      0.25      0.27     23230\n          10       0.36      0.15      0.21     23231\n          11       0.32      0.20      0.25     23230\n          12       0.25      0.18      0.21     23230\n          13       0.33      0.25      0.29     23231\n\n    accuracy                           0.34    325226\n   macro avg       0.36      0.34      0.32    325226\nweighted avg       0.36      0.34      0.32    325226\n\n========================================\n\n\n--- K-Nearest Neighbors ---\n","output_type":"stream"},{"name":"stderr","text":"\nTraining K-Nearest Neighbors:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\nTraining K-Nearest Neighbors: 100%|██████████| 1/1 [00:02<00:00,  2.24s/it]\u001b[A\n","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.8133\n\nClassification Report:\n","output_type":"stream"},{"name":"stderr","text":"Training models:  60%|██████    | 3/5 [24:08<14:25, 432.66s/it]","output_type":"stream"},{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.80      0.89      0.84     23230\n           1       0.87      0.82      0.85     23230\n           2       0.76      0.87      0.81     23230\n           3       0.78      0.77      0.77     23231\n           4       0.83      0.78      0.80     23231\n           5       0.78      0.87      0.82     23230\n           6       0.77      0.82      0.80     23231\n           7       0.89      0.90      0.90     23231\n           8       0.85      0.81      0.83     23230\n           9       0.83      0.77      0.80     23230\n          10       0.81      0.76      0.78     23231\n          11       0.79      0.80      0.79     23230\n          12       0.82      0.78      0.80     23230\n          13       0.84      0.76      0.80     23231\n\n    accuracy                           0.81    325226\n   macro avg       0.82      0.81      0.81    325226\nweighted avg       0.82      0.81      0.81    325226\n\n========================================\n\n\n--- Decision Tree ---\n","output_type":"stream"},{"name":"stderr","text":"\nTraining Decision Tree:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\nTraining Decision Tree: 100%|██████████| 1/1 [00:20<00:00, 20.28s/it]\u001b[A\n","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.8428\n\nClassification Report:\n","output_type":"stream"},{"name":"stderr","text":"Training models:  80%|████████  | 4/5 [24:29<04:30, 270.23s/it]","output_type":"stream"},{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.88      0.88      0.88     23230\n           1       0.89      0.88      0.88     23230\n           2       0.85      0.85      0.85     23230\n           3       0.80      0.81      0.80     23231\n           4       0.84      0.84      0.84     23231\n           5       0.85      0.84      0.84     23230\n           6       0.82      0.82      0.82     23231\n           7       0.92      0.93      0.93     23231\n           8       0.85      0.85      0.85     23230\n           9       0.82      0.82      0.82     23230\n          10       0.81      0.80      0.81     23231\n          11       0.82      0.82      0.82     23230\n          12       0.83      0.83      0.83     23230\n          13       0.83      0.83      0.83     23231\n\n    accuracy                           0.84    325226\n   macro avg       0.84      0.84      0.84    325226\nweighted avg       0.84      0.84      0.84    325226\n\n========================================\n\n\n--- Extra Trees ---\n","output_type":"stream"},{"name":"stderr","text":"\nTraining Extra Trees:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\nTraining Extra Trees:   2%|▏         | 1/50 [00:01<01:21,  1.66s/it]\u001b[A\nTraining Extra Trees:   4%|▍         | 2/50 [00:04<02:02,  2.55s/it]\u001b[A\nTraining Extra Trees:   6%|▌         | 3/50 [00:09<02:44,  3.51s/it]\u001b[A\nTraining Extra Trees:   8%|▊         | 4/50 [00:15<03:28,  4.54s/it]\u001b[A\nTraining Extra Trees:  10%|█         | 5/50 [00:23<04:14,  5.65s/it]\u001b[A\nTraining Extra Trees:  12%|█▏        | 6/50 [00:32<05:01,  6.84s/it]\u001b[A\nTraining Extra Trees:  14%|█▍        | 7/50 [00:43<05:48,  8.11s/it]\u001b[A\nTraining Extra Trees:  16%|█▌        | 8/50 [00:55<06:34,  9.40s/it]\u001b[A\nTraining Extra Trees:  18%|█▊        | 9/50 [01:12<08:01, 11.74s/it]\u001b[A\nTraining Extra Trees:  20%|██        | 10/50 [01:27<08:33, 12.83s/it]\u001b[A\nTraining Extra Trees:  22%|██▏       | 11/50 [01:43<09:04, 13.96s/it]\u001b[A\nTraining Extra Trees:  24%|██▍       | 12/50 [02:02<09:38, 15.23s/it]\u001b[A\nTraining Extra Trees:  26%|██▌       | 13/50 [02:21<10:12, 16.55s/it]\u001b[A\nTraining Extra Trees:  28%|██▊       | 14/50 [02:42<10:43, 17.88s/it]\u001b[A\nTraining Extra Trees:  30%|███       | 15/50 [03:05<11:14, 19.28s/it]\u001b[A\nTraining Extra Trees:  32%|███▏      | 16/50 [03:29<11:43, 20.68s/it]\u001b[A\nTraining Extra Trees:  34%|███▍      | 17/50 [03:54<12:08, 22.08s/it]\u001b[A\nTraining Extra Trees:  36%|███▌      | 18/50 [04:22<12:40, 23.75s/it]\u001b[A\nTraining Extra Trees:  38%|███▊      | 19/50 [04:50<13:04, 25.30s/it]\u001b[A\nTraining Extra Trees:  40%|████      | 20/50 [05:21<13:24, 26.80s/it]\u001b[A\nTraining Extra Trees:  42%|████▏     | 21/50 [05:52<13:39, 28.25s/it]\u001b[A\nTraining Extra Trees:  44%|████▍     | 22/50 [06:26<13:58, 29.96s/it]\u001b[A\nTraining Extra Trees:  46%|████▌     | 23/50 [07:01<14:07, 31.38s/it]\u001b[A\nTraining Extra Trees:  48%|████▊     | 24/50 [07:37<14:14, 32.85s/it]\u001b[A\nTraining Extra Trees:  50%|█████     | 25/50 [08:26<15:42, 37.71s/it]\u001b[A\nTraining Extra Trees:  52%|█████▏    | 26/50 [09:08<15:36, 39.01s/it]\u001b[A\nTraining Extra Trees:  54%|█████▍    | 27/50 [09:50<15:13, 39.73s/it]\u001b[A\nTraining Extra Trees:  56%|█████▌    | 28/50 [10:33<14:53, 40.62s/it]\u001b[A\nTraining Extra Trees:  58%|█████▊    | 29/50 [11:17<14:35, 41.68s/it]\u001b[A\nTraining Extra Trees:  60%|██████    | 30/50 [12:01<14:12, 42.62s/it]\u001b[A\nTraining Extra Trees:  62%|██████▏   | 31/50 [12:47<13:45, 43.46s/it]\u001b[A\nTraining Extra Trees:  64%|██████▍   | 32/50 [13:33<13:17, 44.31s/it]\u001b[A\nTraining Extra Trees:  66%|██████▌   | 33/50 [14:21<12:50, 45.30s/it]\u001b[A\nTraining Extra Trees:  68%|██████▊   | 34/50 [15:10<12:23, 46.45s/it]\u001b[A\nTraining Extra Trees:  70%|███████   | 35/50 [16:01<11:55, 47.70s/it]\u001b[A\nTraining Extra Trees:  72%|███████▏  | 36/50 [16:52<11:24, 48.87s/it]\u001b[A\nTraining Extra Trees:  74%|███████▍  | 37/50 [17:46<10:54, 50.35s/it]\u001b[A\nTraining Extra Trees:  76%|███████▌  | 38/50 [18:52<10:59, 54.95s/it]\u001b[A\nTraining Extra Trees:  78%|███████▊  | 39/50 [19:50<10:14, 55.87s/it]\u001b[A\nTraining Extra Trees:  80%|████████  | 40/50 [20:48<09:25, 56.53s/it]\u001b[A\nTraining Extra Trees:  82%|████████▏ | 41/50 [21:47<08:37, 57.47s/it]\u001b[A\nTraining Extra Trees:  84%|████████▍ | 42/50 [22:48<07:46, 58.30s/it]\u001b[A\nTraining Extra Trees:  86%|████████▌ | 43/50 [23:50<06:56, 59.43s/it]\u001b[A\nTraining Extra Trees:  88%|████████▊ | 44/50 [24:54<06:04, 60.77s/it]\u001b[A\nTraining Extra Trees:  90%|█████████ | 45/50 [26:00<05:11, 62.35s/it]\u001b[A\nTraining Extra Trees:  92%|█████████▏| 46/50 [27:05<04:13, 63.36s/it]\u001b[A\nTraining Extra Trees:  94%|█████████▍| 47/50 [28:13<03:14, 64.78s/it]\u001b[A\nTraining Extra Trees:  96%|█████████▌| 48/50 [29:39<02:21, 70.93s/it]\u001b[A\nTraining Extra Trees:  98%|█████████▊| 49/50 [30:50<01:10, 70.95s/it]\u001b[A\nTraining Extra Trees: 100%|██████████| 50/50 [32:02<00:00, 38.44s/it]\u001b[A\n","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.8768\n\nClassification Report:\n","output_type":"stream"},{"name":"stderr","text":"Training models: 100%|██████████| 5/5 [56:48<00:00, 681.62s/it]","output_type":"stream"},{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.90      0.91      0.90     23230\n           1       0.91      0.91      0.91     23230\n           2       0.87      0.88      0.87     23230\n           3       0.84      0.85      0.84     23231\n           4       0.87      0.87      0.87     23231\n           5       0.88      0.89      0.88     23230\n           6       0.86      0.86      0.86     23231\n           7       0.94      0.94      0.94     23231\n           8       0.88      0.88      0.88     23230\n           9       0.87      0.86      0.86     23230\n          10       0.85      0.84      0.85     23231\n          11       0.86      0.85      0.85     23230\n          12       0.87      0.86      0.87     23230\n          13       0.88      0.87      0.87     23231\n\n    accuracy                           0.88    325226\n   macro avg       0.88      0.88      0.88    325226\nweighted avg       0.88      0.88      0.88    325226\n\n========================================\n\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":38},{"cell_type":"markdown","source":"## Taking the most correlated ones","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Your custom feature columns\ncolumns_array = [\n    \"Flexure extension\",\n    \"Flexure load\",\n    \"Flexure strain\",\n    \"Flexure stress\",\n    \"Extension\",\n    \"Load\",\n    \"Density\"\n]\n\ntarget_col = \"Pattern\"  # categorical target\n\n# Encode the target\ndf_encoded = df_balanced.copy()\ndf_encoded[target_col] = df_encoded[target_col].astype('category').cat.codes\n\n# Select only feature columns + target\nsubset = df_encoded[columns_array + [target_col]]\n\n# Compute correlation with respect to target\ncorr_with_target = subset.corr()[target_col].drop(target_col).sort_values(ascending=False)\n\nprint(\"Correlation with target column:\")\nprint(corr_with_target)\n\n# Plot\nplt.figure(figsize=(8, 5))\nsns.barplot(x=corr_with_target.values, y=corr_with_target.index, palette='coolwarm')\nplt.title(f'Feature Correlation with {target_col} (Encoded)')\nplt.xlabel('Correlation Coefficient')\nplt.ylabel('Feature')\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T16:21:53.020894Z","iopub.execute_input":"2025-08-15T16:21:53.021180Z","iopub.status.idle":"2025-08-15T16:21:54.234269Z","shell.execute_reply.started":"2025-08-15T16:21:53.021154Z","shell.execute_reply":"2025-08-15T16:21:54.233297Z"}},"outputs":[{"name":"stdout","text":"Correlation with target column:\nFlexure strain       0.103244\nFlexure extension    0.103244\nFlexure stress       0.066560\nFlexure load         0.066560\nDensity             -0.032552\nLoad                -0.066560\nExtension           -0.103244\nName: Pattern, dtype: float64\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 800x500 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":72},{"cell_type":"code","source":"# Example: choose specific columns you want\nselected_columns = ['Flexure stress', 'Flexure strain','Pattern']  \n\n# Create new DataFrame with only those columns\ndf_somefeatures = df_balanced[selected_columns].copy()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T16:24:27.285944Z","iopub.execute_input":"2025-08-15T16:24:27.286821Z","iopub.status.idle":"2025-08-15T16:24:27.327628Z","shell.execute_reply.started":"2025-08-15T16:24:27.286790Z","shell.execute_reply":"2025-08-15T16:24:27.326847Z"}},"outputs":[],"execution_count":75},{"cell_type":"code","source":"df_somefeatures","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T16:24:28.362625Z","iopub.execute_input":"2025-08-15T16:24:28.363267Z","iopub.status.idle":"2025-08-15T16:24:28.373215Z","shell.execute_reply.started":"2025-08-15T16:24:28.363233Z","shell.execute_reply":"2025-08-15T16:24:28.372410Z"}},"outputs":[{"execution_count":76,"output_type":"execute_result","data":{"text/plain":"         Flexure stress  Flexure strain  Pattern\n0             -1.335808       -1.124854        0\n1             -0.655425       -0.940459        5\n2             -2.118213       -1.472593        0\n3              1.053744        0.119547        8\n4              0.187928       -0.280590        8\n...                 ...             ...      ...\n1626123        0.387131       -0.319088        2\n1626124        1.017148        0.847008       12\n1626125        0.556219       -0.382637        1\n1626126        0.453211       -0.249243        5\n1626127        0.668908        0.681411        1\n\n[1626128 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Flexure stress</th>\n      <th>Flexure strain</th>\n      <th>Pattern</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-1.335808</td>\n      <td>-1.124854</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.655425</td>\n      <td>-0.940459</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-2.118213</td>\n      <td>-1.472593</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.053744</td>\n      <td>0.119547</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.187928</td>\n      <td>-0.280590</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1626123</th>\n      <td>0.387131</td>\n      <td>-0.319088</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1626124</th>\n      <td>1.017148</td>\n      <td>0.847008</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>1626125</th>\n      <td>0.556219</td>\n      <td>-0.382637</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1626126</th>\n      <td>0.453211</td>\n      <td>-0.249243</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1626127</th>\n      <td>0.668908</td>\n      <td>0.681411</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>1626128 rows × 3 columns</p>\n</div>"},"metadata":{}}],"execution_count":76},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX = df_somefeatures.drop('Pattern', axis=1)\ny = df_somefeatures['Pattern']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T16:24:32.353344Z","iopub.execute_input":"2025-08-15T16:24:32.354097Z","iopub.status.idle":"2025-08-15T16:24:32.510032Z","shell.execute_reply.started":"2025-08-15T16:24:32.354059Z","shell.execute_reply":"2025-08-15T16:24:32.508929Z"}},"outputs":[],"execution_count":77},{"cell_type":"code","source":"print(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T16:24:37.190556Z","iopub.execute_input":"2025-08-15T16:24:37.191267Z","iopub.status.idle":"2025-08-15T16:24:37.196368Z","shell.execute_reply.started":"2025-08-15T16:24:37.191239Z","shell.execute_reply":"2025-08-15T16:24:37.195579Z"}},"outputs":[{"name":"stdout","text":"(1300902, 2)\n(325226, 2)\n(1300902,)\n(325226,)\n","output_type":"stream"}],"execution_count":78},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.gaussian_process.kernels import RBF\n\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom tqdm import trange, tqdm\n\nfrom xgboost import XGBClassifier\n\n# Example dataset (replace with your own)\n# from sklearn.datasets import load_iris\n# from sklearn.model_selection import train_test_split\n# X, y = load_iris(return_X_y=True)\n# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n# Define models\nmodels = {\n    \"Random Forest\": RandomForestClassifier(\n        n_estimators=10,\n        warm_start=True,\n        random_state=42\n    ),\n    \n    # \"AdaBoost\": AdaBoostClassifier(\n    #     n_estimators=10,\n    #     learning_rate=1.0,\n    #     random_state=42\n    # ),\n    \n    \"XGBoost\": XGBClassifier(\n        n_estimators=10,\n        learning_rate=0.1,\n        max_depth=6,\n        random_state=42,\n        use_label_encoder=False,\n        eval_metric='mlogloss'\n    ),\n\n    \"K-Nearest Neighbors\": KNeighborsClassifier(\n        n_neighbors=30,\n        weights='distance',\n        metric='euclidean'\n    ),\n    \n    \"Decision Tree\": DecisionTreeClassifier(\n        random_state=42\n    ),\n    \n    \"Extra Trees\": ExtraTreesClassifier(\n        n_estimators=20,\n        random_state=42\n    )\n}\n\n# Training loop\nfor name, model in tqdm(models.items(), desc=\"Training models\"):\n    print(f\"\\n--- {name} ---\")\n    \n    # Incremental fitting for models with n_estimators\n    if hasattr(model, \"n_estimators\"):\n        n_estimators = model.n_estimators\n        for i in trange(1, n_estimators + 1, desc=f\"Training {name}\"):\n            model.set_params(n_estimators=i)\n            model.fit(X_train, y_train)\n    else:\n        for _ in trange(1, 2, desc=f\"Training {name}\"):\n            model.fit(X_train, y_train)\n    \n    # Predict and evaluate\n    y_pred = model.predict(X_test)\n    print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n    print(\"\\nClassification Report:\")\n    print(classification_report(y_test, y_pred))\n    print(\"=\"*40 + \"\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-15T16:24:47.768336Z","iopub.execute_input":"2025-08-15T16:24:47.768655Z","iopub.status.idle":"2025-08-15T16:34:52.919271Z","shell.execute_reply.started":"2025-08-15T16:24:47.768632Z","shell.execute_reply":"2025-08-15T16:34:52.918338Z"}},"outputs":[{"name":"stderr","text":"Training models:   0%|          | 0/6 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"\n--- Random Forest ---\n","output_type":"stream"},{"name":"stderr","text":"\nTraining Random Forest:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\nTraining Random Forest:  10%|█         | 1/10 [00:05<00:45,  5.01s/it]\u001b[A\nTraining Random Forest:  20%|██        | 2/10 [00:09<00:39,  4.92s/it]\u001b[A\nTraining Random Forest:  30%|███       | 3/10 [00:15<00:35,  5.05s/it]\u001b[A\nTraining Random Forest:  40%|████      | 4/10 [00:20<00:30,  5.03s/it]\u001b[A\nTraining Random Forest:  50%|█████     | 5/10 [00:25<00:25,  5.01s/it]\u001b[A\nTraining Random Forest:  60%|██████    | 6/10 [00:30<00:20,  5.11s/it]\u001b[A\nTraining Random Forest:  70%|███████   | 7/10 [00:35<00:15,  5.09s/it]\u001b[A\nTraining Random Forest:  80%|████████  | 8/10 [00:40<00:10,  5.04s/it]\u001b[A\nTraining Random Forest:  90%|█████████ | 9/10 [00:45<00:05,  5.01s/it]\u001b[A\nTraining Random Forest: 100%|██████████| 10/10 [00:50<00:00,  5.06s/it]\u001b[A\n","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.6251\n\nClassification Report:\n","output_type":"stream"},{"name":"stderr","text":"Training models:  17%|█▋        | 1/6 [00:54<04:32, 54.41s/it]","output_type":"stream"},{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.60      0.67      0.63     23280\n           1       0.61      0.65      0.63     23174\n           2       0.57      0.62      0.59     23325\n           3       0.60      0.62      0.61     23195\n           4       0.62      0.62      0.62     23361\n           5       0.62      0.65      0.64     23096\n           6       0.57      0.58      0.57     23172\n           7       0.69      0.69      0.69     23190\n           8       0.69      0.66      0.67     23046\n           9       0.63      0.60      0.61     23351\n          10       0.62      0.59      0.60     23047\n          11       0.65      0.61      0.63     23361\n          12       0.62      0.58      0.60     23161\n          13       0.68      0.61      0.64     23467\n\n    accuracy                           0.63    325226\n   macro avg       0.63      0.63      0.63    325226\nweighted avg       0.63      0.63      0.63    325226\n\n========================================\n\n\n--- AdaBoost ---\n","output_type":"stream"},{"name":"stderr","text":"\nTraining AdaBoost:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\nTraining AdaBoost:  10%|█         | 1/10 [00:01<00:11,  1.31s/it]\u001b[A\nTraining AdaBoost:  20%|██        | 2/10 [00:04<00:17,  2.14s/it]\u001b[A\nTraining AdaBoost:  30%|███       | 3/10 [00:08<00:21,  3.02s/it]\u001b[A\nTraining AdaBoost:  40%|████      | 4/10 [00:13<00:23,  3.97s/it]\u001b[A\nTraining AdaBoost:  50%|█████     | 5/10 [00:20<00:24,  4.93s/it]\u001b[A\nTraining AdaBoost:  60%|██████    | 6/10 [00:28<00:23,  5.99s/it]\u001b[A\nTraining AdaBoost:  70%|███████   | 7/10 [00:37<00:21,  7.09s/it]\u001b[A\nTraining AdaBoost:  80%|████████  | 8/10 [00:48<00:16,  8.27s/it]\u001b[A\nTraining AdaBoost:  90%|█████████ | 9/10 [01:00<00:09,  9.43s/it]\u001b[A\nTraining AdaBoost: 100%|██████████| 10/10 [01:13<00:00,  7.36s/it]\u001b[A\n","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.1413\n\nClassification Report:\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\nTraining models:  33%|███▎      | 2/6 [02:09<04:25, 66.49s/it]","output_type":"stream"},{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.10      0.54      0.16     23280\n           1       0.42      0.08      0.13     23174\n           2       0.17      0.28      0.21     23325\n           3       0.00      0.00      0.00     23195\n           4       0.18      0.16      0.17     23361\n           5       0.11      0.22      0.15     23096\n           6       0.00      0.00      0.00     23172\n           7       0.25      0.45      0.32     23190\n           8       0.00      0.00      0.00     23046\n           9       0.09      0.03      0.05     23351\n          10       0.14      0.14      0.14     23047\n          11       0.00      0.00      0.00     23361\n          12       0.00      0.00      0.00     23161\n          13       0.14      0.09      0.11     23467\n\n    accuracy                           0.14    325226\n   macro avg       0.11      0.14      0.10    325226\nweighted avg       0.11      0.14      0.10    325226\n\n========================================\n\n\n--- XGBoost ---\n","output_type":"stream"},{"name":"stderr","text":"\nTraining XGBoost:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\nTraining XGBoost:  10%|█         | 1/10 [00:01<00:12,  1.40s/it]\u001b[A\nTraining XGBoost:  20%|██        | 2/10 [00:03<00:14,  1.86s/it]\u001b[A\nTraining XGBoost:  30%|███       | 3/10 [00:06<00:16,  2.39s/it]\u001b[A\nTraining XGBoost:  40%|████      | 4/10 [00:10<00:17,  2.98s/it]\u001b[A\nTraining XGBoost:  50%|█████     | 5/10 [00:15<00:17,  3.56s/it]\u001b[A\nTraining XGBoost:  60%|██████    | 6/10 [00:20<00:16,  4.22s/it]\u001b[A\nTraining XGBoost:  70%|███████   | 7/10 [00:26<00:14,  4.89s/it]\u001b[A\nTraining XGBoost:  80%|████████  | 8/10 [00:33<00:11,  5.60s/it]\u001b[A\nTraining XGBoost:  90%|█████████ | 9/10 [00:41<00:06,  6.36s/it]\u001b[A\nTraining XGBoost: 100%|██████████| 10/10 [00:50<00:00,  5.07s/it]\u001b[A\n","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.2509\n\nClassification Report:\n","output_type":"stream"},{"name":"stderr","text":"Training models:  50%|█████     | 3/6 [03:01<02:59, 59.82s/it]","output_type":"stream"},{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.16      0.77      0.27     23280\n           1       0.36      0.28      0.32     23174\n           2       0.25      0.32      0.28     23325\n           3       0.32      0.18      0.23     23195\n           4       0.38      0.24      0.30     23361\n           5       0.17      0.16      0.17     23096\n           6       0.26      0.14      0.18     23172\n           7       0.33      0.50      0.40     23190\n           8       0.45      0.18      0.26     23046\n           9       0.30      0.17      0.22     23351\n          10       0.23      0.12      0.16     23047\n          11       0.22      0.18      0.20     23361\n          12       0.36      0.14      0.20     23161\n          13       0.53      0.11      0.19     23467\n\n    accuracy                           0.25    325226\n   macro avg       0.31      0.25      0.24    325226\nweighted avg       0.31      0.25      0.24    325226\n\n========================================\n\n\n--- K-Nearest Neighbors ---\n","output_type":"stream"},{"name":"stderr","text":"\nTraining K-Nearest Neighbors:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\nTraining K-Nearest Neighbors: 100%|██████████| 1/1 [00:01<00:00,  1.45s/it]\u001b[A\n","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.6535\n\nClassification Report:\n","output_type":"stream"},{"name":"stderr","text":"Training models:  67%|██████▋   | 4/6 [03:10<01:19, 39.69s/it]","output_type":"stream"},{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.63      0.73      0.68     23280\n           1       0.69      0.65      0.67     23174\n           2       0.60      0.67      0.63     23325\n           3       0.64      0.62      0.63     23195\n           4       0.66      0.64      0.65     23361\n           5       0.63      0.72      0.67     23096\n           6       0.59      0.64      0.61     23172\n           7       0.70      0.72      0.71     23190\n           8       0.72      0.66      0.69     23046\n           9       0.66      0.62      0.64     23351\n          10       0.64      0.61      0.62     23047\n          11       0.66      0.64      0.65     23361\n          12       0.64      0.62      0.63     23161\n          13       0.71      0.62      0.66     23467\n\n    accuracy                           0.65    325226\n   macro avg       0.66      0.65      0.65    325226\nweighted avg       0.66      0.65      0.65    325226\n\n========================================\n\n\n--- Decision Tree ---\n","output_type":"stream"},{"name":"stderr","text":"\nTraining Decision Tree:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\nTraining Decision Tree: 100%|██████████| 1/1 [00:12<00:00, 12.66s/it]\u001b[A\n","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.6306\n\nClassification Report:\n","output_type":"stream"},{"name":"stderr","text":"Training models:  83%|████████▎ | 5/6 [03:23<00:30, 30.31s/it]","output_type":"stream"},{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.65      0.64      0.64     23280\n           1       0.64      0.64      0.64     23174\n           2       0.60      0.60      0.60     23325\n           3       0.61      0.61      0.61     23195\n           4       0.63      0.63      0.63     23361\n           5       0.63      0.64      0.64     23096\n           6       0.58      0.58      0.58     23172\n           7       0.69      0.69      0.69     23190\n           8       0.67      0.68      0.67     23046\n           9       0.62      0.62      0.62     23351\n          10       0.61      0.61      0.61     23047\n          11       0.63      0.63      0.63     23361\n          12       0.61      0.60      0.61     23161\n          13       0.65      0.64      0.65     23467\n\n    accuracy                           0.63    325226\n   macro avg       0.63      0.63      0.63    325226\nweighted avg       0.63      0.63      0.63    325226\n\n========================================\n\n\n--- Extra Trees ---\n","output_type":"stream"},{"name":"stderr","text":"\nTraining Extra Trees:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\nTraining Extra Trees:   5%|▌         | 1/20 [00:01<00:37,  1.97s/it]\u001b[A\nTraining Extra Trees:  10%|█         | 2/20 [00:05<00:56,  3.13s/it]\u001b[A\nTraining Extra Trees:  15%|█▌        | 3/20 [00:11<01:13,  4.33s/it]\u001b[A\nTraining Extra Trees:  20%|██        | 4/20 [00:19<01:30,  5.67s/it]\u001b[A\nTraining Extra Trees:  25%|██▌       | 5/20 [00:28<01:44,  6.99s/it]\u001b[A\nTraining Extra Trees:  30%|███       | 6/20 [00:39<01:58,  8.45s/it]\u001b[A\nTraining Extra Trees:  35%|███▌      | 7/20 [00:53<02:09,  9.95s/it]\u001b[A\nTraining Extra Trees:  40%|████      | 8/20 [01:07<02:18, 11.54s/it]\u001b[A\nTraining Extra Trees:  45%|████▌     | 9/20 [01:24<02:24, 13.16s/it]\u001b[A\nTraining Extra Trees:  50%|█████     | 10/20 [01:43<02:28, 14.83s/it]\u001b[A\nTraining Extra Trees:  55%|█████▌    | 11/20 [02:03<02:29, 16.59s/it]\u001b[A\nTraining Extra Trees:  60%|██████    | 12/20 [02:26<02:27, 18.46s/it]\u001b[A\nTraining Extra Trees:  65%|██████▌   | 13/20 [02:51<02:22, 20.33s/it]\u001b[A\nTraining Extra Trees:  70%|███████   | 14/20 [03:17<02:13, 22.18s/it]\u001b[A\nTraining Extra Trees:  75%|███████▌  | 15/20 [03:46<02:00, 24.04s/it]\u001b[A\nTraining Extra Trees:  80%|████████  | 16/20 [04:15<01:43, 25.79s/it]\u001b[A\nTraining Extra Trees:  85%|████████▌ | 17/20 [04:47<01:22, 27.55s/it]\u001b[A\nTraining Extra Trees:  90%|█████████ | 18/20 [05:21<00:58, 29.45s/it]\u001b[A\nTraining Extra Trees:  95%|█████████▌| 19/20 [05:56<00:31, 31.28s/it]\u001b[A\nTraining Extra Trees: 100%|██████████| 20/20 [06:33<00:00, 19.70s/it]\u001b[A\n","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.6218\n\nClassification Report:\n","output_type":"stream"},{"name":"stderr","text":"Training models: 100%|██████████| 6/6 [10:05<00:00, 100.85s/it]","output_type":"stream"},{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.61      0.66      0.63     23280\n           1       0.63      0.64      0.63     23174\n           2       0.57      0.60      0.59     23325\n           3       0.60      0.60      0.60     23195\n           4       0.62      0.62      0.62     23361\n           5       0.62      0.65      0.63     23096\n           6       0.56      0.57      0.57     23172\n           7       0.68      0.69      0.68     23190\n           8       0.68      0.66      0.67     23046\n           9       0.62      0.60      0.61     23351\n          10       0.61      0.59      0.60     23047\n          11       0.64      0.62      0.63     23361\n          12       0.61      0.58      0.60     23161\n          13       0.67      0.62      0.64     23467\n\n    accuracy                           0.62    325226\n   macro avg       0.62      0.62      0.62    325226\nweighted avg       0.62      0.62      0.62    325226\n\n========================================\n\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":79},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}